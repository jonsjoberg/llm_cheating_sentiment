ggml_metal_device_init: tensor API disabled for pre-M5 and pre-A19 devices
ggml_metal_library_init: using embedded metal library
ggml_metal_library_init: loaded in 0.020 sec
ggml_metal_rsets_init: creating a residency set collection (keep_alive = 180 s)
ggml_metal_device_init: GPU name:   MTL0
ggml_metal_device_init: GPU family: MTLGPUFamilyApple9  (1009)
ggml_metal_device_init: GPU family: MTLGPUFamilyCommon3 (3003)
ggml_metal_device_init: GPU family: MTLGPUFamilyMetal4  (5002)
ggml_metal_device_init: simdgroup reduction   = true
ggml_metal_device_init: simdgroup matrix mul. = true
ggml_metal_device_init: has unified memory    = true
ggml_metal_device_init: has bfloat            = true
ggml_metal_device_init: has tensor            = false
ggml_metal_device_init: use residency sets    = true
ggml_metal_device_init: use shared buffers    = true
ggml_metal_device_init: recommendedMaxWorkingSetSize  = 30150.67 MB
common_download_file_single_online: no previous model file found /Users/jonsjoberg/Library/Caches/llama.cpp/Mungert_Mistral-Small-3.1-24B-Instruct-2503-GGUF_preset.ini
common_download_file_single_online: HEAD invalid http status code received: 404
no remote preset found, skipping
common_download_file_single_online: using cached file: /Users/jonsjoberg/Library/Caches/llama.cpp/Mungert_Mistral-Small-3.1-24B-Instruct-2503-GGUF_Mistral-Small-3.1-24B-Instruct-2503-q4_k_m.gguf
main: n_parallel is set to auto, using n_parallel = 4 and kv_unified = true
build: 7960 (db6adb3c8) with AppleClang 17.0.0.17000603 for Darwin arm64
system info: n_threads = 6, n_threads_batch = 6, total_threads = 12

system_info: n_threads = 6 (n_threads_batch = 6) / 12 | MTL : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | LLAMAFILE = 1 | ACCELERATE = 1 | REPACK = 1 | 

Running without SSL
init: using 11 threads for HTTP server
start: binding port with default address family
main: loading model
srv    load_model: loading model '/Users/jonsjoberg/Library/Caches/llama.cpp/Mungert_Mistral-Small-3.1-24B-Instruct-2503-GGUF_Mistral-Small-3.1-24B-Instruct-2503-q4_k_m.gguf'
common_init_result: fitting params to device memory, for bugs during this step try to reproduce them with -fit off, or provide --verbose logs if the bug only occurs with -fit on
llama_params_fit_impl: projected to use 34041 MiB of device memory vs. 28753 MiB of free device memory
llama_params_fit_impl: cannot meet free memory target of 1024 MiB, need to reduce device memory by 6311 MiB
llama_params_fit_impl: context size reduced from 131072 to 90880 -> need 6326 MiB less memory in total
llama_params_fit_impl: entire model can be fit by reducing context
llama_params_fit: successfully fit params to free device memory
llama_params_fit: fitting params to free memory took 0.32 seconds
llama_model_load_from_file_impl: using device MTL0 (Apple M3 Pro) (unknown id) - 28753 MiB free
llama_model_loader: loaded meta data with 47 key-value pairs and 363 tensors from /Users/jonsjoberg/Library/Caches/llama.cpp/Mungert_Mistral-Small-3.1-24B-Instruct-2503-GGUF_Mistral-Small-3.1-24B-Instruct-2503-q4_k_m.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Mistral-Small-3.1-24B-Instruct-2503
llama_model_loader: - kv   3:                           general.finetune str              = 73ce7c62b904fa83d7cb018e44c3bc06feed4d81
llama_model_loader: - kv   4:                         general.size_label str              = 24B
llama_model_loader: - kv   5:                            general.license str              = apache-2.0
llama_model_loader: - kv   6:                   general.base_model.count u32              = 1
llama_model_loader: - kv   7:                  general.base_model.0.name str              = Mistral Small 3.1 24B Base 2503
llama_model_loader: - kv   8:               general.base_model.0.version str              = 2503
llama_model_loader: - kv   9:          general.base_model.0.organization str              = Mistralai
llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/mistralai/Mist...
llama_model_loader: - kv  11:                               general.tags arr[str,1]       = ["image-text-to-text"]
llama_model_loader: - kv  12:                          general.languages arr[str,24]      = ["en", "fr", "de", "es", "pt", "it", ...
llama_model_loader: - kv  13:                          llama.block_count u32              = 40
llama_model_loader: - kv  14:                       llama.context_length u32              = 131072
llama_model_loader: - kv  15:                     llama.embedding_length u32              = 5120
llama_model_loader: - kv  16:                  llama.feed_forward_length u32              = 32768
llama_model_loader: - kv  17:                 llama.attention.head_count u32              = 32
llama_model_loader: - kv  18:              llama.attention.head_count_kv u32              = 8
llama_model_loader: - kv  19:                       llama.rope.freq_base f32              = 1000000000.000000
llama_model_loader: - kv  20:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  21:                 llama.attention.key_length u32              = 128
llama_model_loader: - kv  22:               llama.attention.value_length u32              = 128
llama_model_loader: - kv  23:                           llama.vocab_size u32              = 131072
llama_model_loader: - kv  24:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv  25:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  26:                         tokenizer.ggml.pre str              = tekken
llama_model_loader: - kv  27:                      tokenizer.ggml.tokens arr[str,131072]  = ["<unk>", "<s>", "</s>", "[INST]", "[...
llama_model_loader: - kv  28:                  tokenizer.ggml.token_type arr[i32,131072]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  29:                      tokenizer.ggml.merges arr[str,269443]  = ["Ä  Ä ", "Ä  t", "e r", "i n", "Ä  Ä...
llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  31:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  32:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  33:            tokenizer.ggml.padding_token_id u32              = 11
llama_model_loader: - kv  34:               tokenizer.ggml.add_bos_token bool             = true
llama_model_loader: - kv  35:               tokenizer.ggml.add_eos_token bool             = false
llama_model_loader: - kv  36:                    tokenizer.chat_template str              = {%- set today = strftime_now("%Y-%m-%...
llama_model_loader: - kv  37:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  38:                       general.quantized_by str              = Mungert
llama_model_loader: - kv  39:                           general.repo_url str              = https://huggingface.co/mungert
llama_model_loader: - kv  40:                        general.sponsor_url str              = https://readyforquantum.com
llama_model_loader: - kv  41:               general.quantization_version u32              = 2
llama_model_loader: - kv  42:                          general.file_type u32              = 15
llama_model_loader: - kv  43:                      quantize.imatrix.file str              = /home/mahadeva/code/models/Mistral-Sm...
llama_model_loader: - kv  44:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt
llama_model_loader: - kv  45:             quantize.imatrix.entries_count i32              = 280
llama_model_loader: - kv  46:              quantize.imatrix.chunks_count i32              = 128
llama_model_loader: - type  f32:   81 tensors
llama_model_loader: - type q4_K:  232 tensors
llama_model_loader: - type q5_K:   24 tensors
llama_model_loader: - type q6_K:   26 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 13.35 GiB (4.87 BPW) 
load: 0 unused tokens
load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: printing all EOG tokens:
load:   - 2 ('</s>')
load: special tokens cache size = 1000
load: token to piece cache size = 0.8498 MB
print_info: arch                  = llama
print_info: vocab_only            = 0
print_info: no_alloc              = 0
print_info: n_ctx_train           = 131072
print_info: n_embd                = 5120
print_info: n_embd_inp            = 5120
print_info: n_layer               = 40
print_info: n_head                = 32
print_info: n_head_kv             = 8
print_info: n_rot                 = 128
print_info: n_swa                 = 0
print_info: is_swa_any            = 0
print_info: n_embd_head_k         = 128
print_info: n_embd_head_v         = 128
print_info: n_gqa                 = 4
print_info: n_embd_k_gqa          = 1024
print_info: n_embd_v_gqa          = 1024
print_info: f_norm_eps            = 0.0e+00
print_info: f_norm_rms_eps        = 1.0e-05
print_info: f_clamp_kqv           = 0.0e+00
print_info: f_max_alibi_bias      = 0.0e+00
print_info: f_logit_scale         = 0.0e+00
print_info: f_attn_scale          = 0.0e+00
print_info: n_ff                  = 32768
print_info: n_expert              = 0
print_info: n_expert_used         = 0
print_info: n_expert_groups       = 0
print_info: n_group_used          = 0
print_info: causal attn           = 1
print_info: pooling type          = 0
print_info: rope type             = 0
print_info: rope scaling          = linear
print_info: freq_base_train       = 1000000000.0
print_info: freq_scale_train      = 1
print_info: n_ctx_orig_yarn       = 131072
print_info: rope_yarn_log_mul     = 0.0000
print_info: rope_finetuned        = unknown
print_info: model type            = 13B
print_info: model params          = 23.57 B
print_info: general.name          = Mistral-Small-3.1-24B-Instruct-2503
print_info: vocab type            = BPE
print_info: n_vocab               = 131072
print_info: n_merges              = 269443
print_info: BOS token             = 1 '<s>'
print_info: EOS token             = 2 '</s>'
print_info: UNK token             = 0 '<unk>'
print_info: PAD token             = 11 '<pad>'
print_info: LF token              = 1010 'ÄŠ'
print_info: EOG token             = 2 '</s>'
print_info: max token length      = 150
load_tensors: loading model tensors, this can take a while... (mmap = true, direct_io = false)
load_tensors: offloading output layer to GPU
load_tensors: offloading 39 repeating layers to GPU
load_tensors: offloaded 41/41 layers to GPU
load_tensors:   CPU_Mapped model buffer size =   525.00 MiB
load_tensors:  MTL0_Mapped model buffer size = 13672.05 MiB
...............................................................................................
common_init_result: added </s> logit bias = -inf
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 90880
llama_context: n_ctx_seq     = 90880
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = auto
llama_context: kv_unified    = true
llama_context: freq_base     = 1000000000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_seq (90880) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M3 Pro
ggml_metal_init: picking default device: Apple M3 Pro
ggml_metal_init: use fusion         = true
ggml_metal_init: use concurrency    = true
ggml_metal_init: use graph optimize = true
llama_context:        CPU  output buffer size =     2.00 MiB
llama_kv_cache:       MTL0 KV buffer size = 14200.00 MiB
llama_kv_cache: size = 14200.00 MiB ( 90880 cells,  40 layers,  4/1 seqs), K (f16): 7100.00 MiB, V (f16): 7100.00 MiB
sched_reserve: reserving ...
sched_reserve: Flash Attention was auto, set to enabled
sched_reserve:       MTL0 compute buffer size =   348.26 MiB
sched_reserve:        CPU compute buffer size =   197.51 MiB
sched_reserve: graph nodes  = 1247
sched_reserve: graph splits = 2
sched_reserve: reserve took 80.65 ms, sched copies = 1
common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)
srv    load_model: initializing slots, n_slots = 4
no implementations specified for speculative decoding
slot   load_model: id  0 | task -1 | speculative decoding context not initialized
slot   load_model: id  0 | task -1 | new slot, n_ctx = 90880
no implementations specified for speculative decoding
slot   load_model: id  1 | task -1 | speculative decoding context not initialized
slot   load_model: id  1 | task -1 | new slot, n_ctx = 90880
no implementations specified for speculative decoding
slot   load_model: id  2 | task -1 | speculative decoding context not initialized
slot   load_model: id  2 | task -1 | new slot, n_ctx = 90880
no implementations specified for speculative decoding
slot   load_model: id  3 | task -1 | speculative decoding context not initialized
slot   load_model: id  3 | task -1 | new slot, n_ctx = 90880
srv    load_model: prompt cache is enabled, size limit: 8192 MiB
srv    load_model: use `--cache-ram 0` to disable the prompt cache
srv    load_model: for more info see https://github.com/ggml-org/llama.cpp/pull/16391
init: chat template, example_format: '[SYSTEM_PROMPT]You are a helpful assistant[/SYSTEM_PROMPT][INST]Hello[/INST]Hi there</s>[INST]How are you?[/INST]'
srv          init: init: chat template, thinking = 0
main: model loaded
main: server is listening on http://127.0.0.1:8080
main: starting the main loop...
srv  update_slots: all slots are idle
srv  params_from_: Chat format: Content-only
slot get_availabl: id  3 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 0 | processing task, is_child = 0
slot update_slots: id  3 | task 0 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 619
slot update_slots: id  3 | task 0 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 619, batch.n_tokens = 619, progress = 1.000000
slot update_slots: id  3 | task 0 | prompt done, n_tokens = 619, batch.n_tokens = 619
slot init_sampler: id  3 | task 0 | init sampler, took 0.10 ms, tokens: text = 619, total = 619
slot print_timing: id  3 | task 0 | 
prompt eval time =    5713.90 ms /   619 tokens (    9.23 ms per token,   108.33 tokens per second)
       eval time =     974.03 ms /    10 tokens (   97.40 ms per token,    10.27 tokens per second)
      total time =    6687.94 ms /   629 tokens
slot      release: id  3 | task 0 | stop processing: n_tokens = 628, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.778 (> 0.100 thold), f_keep = 0.123
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 628, total state size = 98.133 MiB
srv          load:  - looking for better prompt, base f_keep = 0.123, sim = 0.778
srv        update:  - cache state: 1 prompts, 98.133 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv  get_availabl: prompt cache update took 20.34 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 11 | processing task, is_child = 0
slot update_slots: id  3 | task 11 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 99
slot update_slots: id  3 | task 11 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 11 | prompt processing progress, n_tokens = 99, batch.n_tokens = 22, progress = 1.000000
slot update_slots: id  3 | task 11 | prompt done, n_tokens = 99, batch.n_tokens = 22
slot init_sampler: id  3 | task 11 | init sampler, took 0.02 ms, tokens: text = 99, total = 99
slot print_timing: id  3 | task 11 | 
prompt eval time =     546.07 ms /    22 tokens (   24.82 ms per token,    40.29 tokens per second)
       eval time =    1441.86 ms /    14 tokens (  102.99 ms per token,     9.71 tokens per second)
      total time =    1987.93 ms /    36 tokens
slot      release: id  3 | task 11 | stop processing: n_tokens = 112, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.500 (> 0.100 thold), f_keep = 0.688
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 26 | processing task, is_child = 0
slot update_slots: id  3 | task 26 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 154
slot update_slots: id  3 | task 26 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 26 | prompt processing progress, n_tokens = 154, batch.n_tokens = 77, progress = 1.000000
slot update_slots: id  3 | task 26 | prompt done, n_tokens = 154, batch.n_tokens = 77
slot init_sampler: id  3 | task 26 | init sampler, took 0.03 ms, tokens: text = 154, total = 154
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot get_availabl: id  2 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 28 | processing task, is_child = 0
slot get_availabl: id  1 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 29 | processing task, is_child = 0
slot get_availabl: id  0 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 30 | processing task, is_child = 0
slot update_slots: id  0 | task 30 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  0 | task 30 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  0 | task 30 | prompt processing progress, n_tokens = 81, batch.n_tokens = 82, progress = 1.000000
slot update_slots: id  0 | task 30 | prompt done, n_tokens = 81, batch.n_tokens = 82
slot init_sampler: id  0 | task 30 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot update_slots: id  1 | task 29 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  1 | task 29 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  1 | task 29 | prompt processing progress, n_tokens = 81, batch.n_tokens = 163, progress = 1.000000
slot update_slots: id  1 | task 29 | prompt done, n_tokens = 81, batch.n_tokens = 163
slot init_sampler: id  1 | task 29 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot update_slots: id  2 | task 28 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 87
slot update_slots: id  2 | task 28 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 28 | prompt processing progress, n_tokens = 87, batch.n_tokens = 250, progress = 1.000000
slot update_slots: id  2 | task 28 | prompt done, n_tokens = 87, batch.n_tokens = 250
slot init_sampler: id  2 | task 28 | init sampler, took 0.01 ms, tokens: text = 87, total = 87
slot print_timing: id  0 | task 30 | 
prompt eval time =    2276.01 ms /    81 tokens (   28.10 ms per token,    35.59 tokens per second)
       eval time =    2639.13 ms /    10 tokens (  263.91 ms per token,     3.79 tokens per second)
      total time =    4915.14 ms /    91 tokens
slot      release: id  0 | task 30 | stop processing: n_tokens = 90, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 26 | 
prompt eval time =     893.26 ms /    77 tokens (   11.60 ms per token,    86.20 tokens per second)
       eval time =    4915.94 ms /    11 tokens (  446.90 ms per token,     2.24 tokens per second)
      total time =    5809.20 ms /    88 tokens
slot      release: id  3 | task 26 | stop processing: n_tokens = 164, truncated = 0
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.837 (> 0.100 thold), f_keep = 0.856
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 32 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.470
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 164, total state size = 25.628 MiB
srv          load:  - looking for better prompt, base f_keep = 0.470, sim = 0.962
srv        update:  - cache state: 2 prompts, 123.761 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv  get_availabl: prompt cache update took 4.04 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 31 | processing task, is_child = 0
slot update_slots: id  0 | task 32 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 92
slot update_slots: id  0 | task 32 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 32 | prompt processing progress, n_tokens = 92, batch.n_tokens = 17, progress = 1.000000
slot update_slots: id  0 | task 32 | prompt done, n_tokens = 92, batch.n_tokens = 17
slot init_sampler: id  0 | task 32 | init sampler, took 0.01 ms, tokens: text = 92, total = 92
slot update_slots: id  3 | task 31 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 80
slot update_slots: id  3 | task 31 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 31 | prompt processing progress, n_tokens = 80, batch.n_tokens = 20, progress = 1.000000
slot update_slots: id  3 | task 31 | prompt done, n_tokens = 80, batch.n_tokens = 20
slot init_sampler: id  3 | task 31 | init sampler, took 0.01 ms, tokens: text = 80, total = 80
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 29 | 
prompt eval time =    2276.19 ms /    81 tokens (   28.10 ms per token,    35.59 tokens per second)
       eval time =    3563.02 ms /    13 tokens (  274.08 ms per token,     3.65 tokens per second)
      total time =    5839.21 ms /    94 tokens
slot      release: id  1 | task 29 | stop processing: n_tokens = 93, truncated = 0
slot print_timing: id  2 | task 28 | 
prompt eval time =    2283.26 ms /    87 tokens (   26.24 ms per token,    38.10 tokens per second)
       eval time =    3556.11 ms /    13 tokens (  273.55 ms per token,     3.66 tokens per second)
      total time =    5839.36 ms /   100 tokens
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 28 | stop processing: n_tokens = 99, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.828
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 34 | processing task, is_child = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.313 (> 0.100 thold), f_keep = 0.778
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 33 | processing task, is_child = 0
slot update_slots: id  1 | task 34 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  1 | task 34 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 34 | prompt processing progress, n_tokens = 81, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  1 | task 34 | prompt done, n_tokens = 81, batch.n_tokens = 6
slot init_sampler: id  1 | task 34 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot update_slots: id  2 | task 33 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 246
slot update_slots: id  2 | task 33 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 33 | prompt processing progress, n_tokens = 246, batch.n_tokens = 175, progress = 1.000000
slot update_slots: id  2 | task 33 | prompt done, n_tokens = 246, batch.n_tokens = 175
slot init_sampler: id  2 | task 33 | init sampler, took 0.03 ms, tokens: text = 246, total = 246
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 31 | 
prompt eval time =     341.37 ms /     3 tokens (  113.79 ms per token,     8.79 tokens per second)
       eval time =    4052.59 ms /    10 tokens (  405.26 ms per token,     2.47 tokens per second)
      total time =    4393.96 ms /    13 tokens
slot      release: id  3 | task 31 | stop processing: n_tokens = 89, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.865
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 35 | processing task, is_child = 0
slot update_slots: id  3 | task 35 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  3 | task 35 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 35 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  3 | task 35 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  3 | task 35 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 32 | 
prompt eval time =     334.15 ms /    15 tokens (   22.28 ms per token,    44.89 tokens per second)
       eval time =    5430.99 ms /    14 tokens (  387.93 ms per token,     2.58 tokens per second)
      total time =    5765.14 ms /    29 tokens
slot      release: id  0 | task 32 | stop processing: n_tokens = 105, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  1 | task 34 | 
prompt eval time =    1727.00 ms /     4 tokens (  431.75 ms per token,     2.32 tokens per second)
       eval time =    3118.60 ms /    11 tokens (  283.51 ms per token,     3.53 tokens per second)
      total time =    4845.60 ms /    15 tokens
slot      release: id  1 | task 34 | stop processing: n_tokens = 91, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.733 (> 0.100 thold), f_keep = 0.733
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 48 | processing task, is_child = 0
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.570 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 36 | processing task, is_child = 0
slot update_slots: id  0 | task 48 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 105
slot update_slots: id  0 | task 48 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 48 | prompt processing progress, n_tokens = 105, batch.n_tokens = 30, progress = 1.000000
slot update_slots: id  0 | task 48 | prompt done, n_tokens = 105, batch.n_tokens = 30
slot init_sampler: id  0 | task 48 | init sampler, took 0.01 ms, tokens: text = 105, total = 105
slot update_slots: id  1 | task 36 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 135
slot update_slots: id  1 | task 36 | n_tokens = 77, memory_seq_rm [77, end)
srv  params_from_: Chat format: Content-only
slot update_slots: id  1 | task 36 | prompt processing progress, n_tokens = 135, batch.n_tokens = 88, progress = 1.000000
slot update_slots: id  1 | task 36 | prompt done, n_tokens = 135, batch.n_tokens = 88
slot init_sampler: id  1 | task 36 | init sampler, took 0.01 ms, tokens: text = 135, total = 135
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 33 | 
prompt eval time =    1733.94 ms /   169 tokens (   10.26 ms per token,    97.47 tokens per second)
       eval time =    4316.60 ms /    13 tokens (  332.05 ms per token,     3.01 tokens per second)
      total time =    6050.54 ms /   182 tokens
slot      release: id  2 | task 33 | stop processing: n_tokens = 258, truncated = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.939 (> 0.100 thold), f_keep = 0.298
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 258, total state size = 40.316 MiB
srv          load:  - looking for better prompt, base f_keep = 0.298, sim = 0.939
srv        update:  - cache state: 3 prompts, 164.077 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv  get_availabl: prompt cache update took 4.57 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 49 | processing task, is_child = 0
slot update_slots: id  2 | task 49 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 82
slot update_slots: id  2 | task 49 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 49 | prompt processing progress, n_tokens = 82, batch.n_tokens = 8, progress = 1.000000
slot update_slots: id  2 | task 49 | prompt done, n_tokens = 82, batch.n_tokens = 8
slot init_sampler: id  2 | task 49 | init sampler, took 0.01 ms, tokens: text = 82, total = 82
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 48 | 
prompt eval time =     897.39 ms /    28 tokens (   32.05 ms per token,    31.20 tokens per second)
       eval time =    2910.34 ms /    10 tokens (  291.03 ms per token,     3.44 tokens per second)
      total time =    3807.73 ms /    38 tokens
slot      release: id  0 | task 48 | stop processing: n_tokens = 114, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.875 (> 0.100 thold), f_keep = 0.675
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 53 | processing task, is_child = 0
slot update_slots: id  0 | task 53 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 88
slot update_slots: id  0 | task 53 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 53 | prompt processing progress, n_tokens = 88, batch.n_tokens = 14, progress = 1.000000
slot update_slots: id  0 | task 53 | prompt done, n_tokens = 88, batch.n_tokens = 14
slot init_sampler: id  0 | task 53 | init sampler, took 0.01 ms, tokens: text = 88, total = 88
slot print_timing: id  3 | task 35 | 
prompt eval time =     513.19 ms /     4 tokens (  128.30 ms per token,     7.79 tokens per second)
       eval time =    5018.43 ms /    15 tokens (  334.56 ms per token,     2.99 tokens per second)
      total time =    5531.62 ms /    19 tokens
slot      release: id  3 | task 35 | stop processing: n_tokens = 95, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.713 (> 0.100 thold), f_keep = 0.811
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 54 | processing task, is_child = 0
slot update_slots: id  3 | task 54 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 108
slot update_slots: id  3 | task 54 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 54 | prompt processing progress, n_tokens = 108, batch.n_tokens = 34, progress = 1.000000
slot update_slots: id  3 | task 54 | prompt done, n_tokens = 108, batch.n_tokens = 34
slot init_sampler: id  3 | task 54 | init sampler, took 0.01 ms, tokens: text = 108, total = 108
slot print_timing: id  1 | task 36 | 
prompt eval time =     904.04 ms /    58 tokens (   15.59 ms per token,    64.16 tokens per second)
       eval time =    3842.73 ms /    12 tokens (  320.23 ms per token,     3.12 tokens per second)
      total time =    4746.77 ms /    70 tokens
slot      release: id  1 | task 36 | stop processing: n_tokens = 146, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.527
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 62 | processing task, is_child = 0
slot update_slots: id  1 | task 62 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 80
slot update_slots: id  1 | task 62 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 62 | prompt processing progress, n_tokens = 80, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  1 | task 62 | prompt done, n_tokens = 80, batch.n_tokens = 6
slot init_sampler: id  1 | task 62 | init sampler, took 0.01 ms, tokens: text = 80, total = 80
slot print_timing: id  2 | task 49 | 
prompt eval time =     568.17 ms /     5 tokens (  113.63 ms per token,     8.80 tokens per second)
       eval time =    4263.79 ms /    14 tokens (  304.56 ms per token,     3.28 tokens per second)
      total time =    4831.96 ms /    19 tokens
slot      release: id  2 | task 49 | stop processing: n_tokens = 95, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.524 (> 0.100 thold), f_keep = 0.811
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 67 | processing task, is_child = 0
slot update_slots: id  2 | task 67 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 147
slot update_slots: id  2 | task 67 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 67 | prompt processing progress, n_tokens = 147, batch.n_tokens = 73, progress = 1.000000
slot update_slots: id  2 | task 67 | prompt done, n_tokens = 147, batch.n_tokens = 73
slot init_sampler: id  2 | task 67 | init sampler, took 0.01 ms, tokens: text = 147, total = 147
slot print_timing: id  1 | task 62 | 
prompt eval time =     407.41 ms /     3 tokens (  135.80 ms per token,     7.36 tokens per second)
       eval time =    3503.81 ms /    11 tokens (  318.53 ms per token,     3.14 tokens per second)
      total time =    3911.22 ms /    14 tokens
slot      release: id  1 | task 62 | stop processing: n_tokens = 90, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.856
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 68 | processing task, is_child = 0
slot update_slots: id  1 | task 68 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 79
slot update_slots: id  1 | task 68 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 68 | prompt processing progress, n_tokens = 79, batch.n_tokens = 5, progress = 1.000000
slot update_slots: id  1 | task 68 | prompt done, n_tokens = 79, batch.n_tokens = 5
slot init_sampler: id  1 | task 68 | init sampler, took 0.01 ms, tokens: text = 79, total = 79
slot print_timing: id  0 | task 53 | 
prompt eval time =     344.37 ms /    11 tokens (   31.31 ms per token,    31.94 tokens per second)
       eval time =    4903.93 ms /    14 tokens (  350.28 ms per token,     2.85 tokens per second)
      total time =    5248.30 ms /    25 tokens
slot      release: id  0 | task 53 | stop processing: n_tokens = 101, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.762
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 71 | processing task, is_child = 0
slot update_slots: id  0 | task 71 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 85
slot update_slots: id  0 | task 71 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 71 | prompt processing progress, n_tokens = 85, batch.n_tokens = 11, progress = 1.000000
slot update_slots: id  0 | task 71 | prompt done, n_tokens = 85, batch.n_tokens = 11
slot init_sampler: id  0 | task 71 | init sampler, took 0.01 ms, tokens: text = 85, total = 85
slot print_timing: id  3 | task 54 | 
prompt eval time =     600.91 ms /    31 tokens (   19.38 ms per token,    51.59 tokens per second)
       eval time =    4943.75 ms /    15 tokens (  329.58 ms per token,     3.03 tokens per second)
      total time =    5544.66 ms /    46 tokens
slot      release: id  3 | task 54 | stop processing: n_tokens = 122, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 67 | 
prompt eval time =     897.77 ms /    70 tokens (   12.83 ms per token,    77.97 tokens per second)
       eval time =    3533.54 ms /    14 tokens (  252.40 ms per token,     3.96 tokens per second)
      total time =    4431.31 ms /    84 tokens
slot      release: id  2 | task 67 | stop processing: n_tokens = 160, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  0 | task 71 | 
prompt eval time =     333.87 ms /     8 tokens (   41.73 ms per token,    23.96 tokens per second)
       eval time =    1698.96 ms /    11 tokens (  154.45 ms per token,     6.47 tokens per second)
      total time =    2032.83 ms /    19 tokens
slot      release: id  0 | task 71 | stop processing: n_tokens = 95, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  1 | task 68 | 
prompt eval time =     397.71 ms /     2 tokens (  198.85 ms per token,     5.03 tokens per second)
       eval time =    2148.52 ms /    13 tokens (  165.27 ms per token,     6.05 tokens per second)
      total time =    2546.23 ms /    15 tokens
slot      release: id  1 | task 68 | stop processing: n_tokens = 91, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.811
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 105 | processing task, is_child = 0
slot update_slots: id  0 | task 105 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  0 | task 105 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 105 | prompt processing progress, n_tokens = 81, batch.n_tokens = 4, progress = 1.000000
slot update_slots: id  0 | task 105 | prompt done, n_tokens = 81, batch.n_tokens = 4
slot init_sampler: id  0 | task 105 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot print_timing: id  0 | task 105 | 
prompt eval time =     636.97 ms /     4 tokens (  159.24 ms per token,     6.28 tokens per second)
       eval time =    1375.52 ms /    11 tokens (  125.05 ms per token,     8.00 tokens per second)
      total time =    2012.49 ms /    15 tokens
slot      release: id  0 | task 105 | stop processing: n_tokens = 91, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 117 | processing task, is_child = 0
slot update_slots: id  0 | task 117 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 80
slot update_slots: id  0 | task 117 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 117 | prompt processing progress, n_tokens = 80, batch.n_tokens = 3, progress = 1.000000
slot update_slots: id  0 | task 117 | prompt done, n_tokens = 80, batch.n_tokens = 3
slot init_sampler: id  0 | task 117 | init sampler, took 0.01 ms, tokens: text = 80, total = 80
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.885 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 119 | processing task, is_child = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.481
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 160, total state size = 25.003 MiB
srv          load:  - looking for better prompt, base f_keep = 0.481, sim = 0.951
srv        update:  - cache state: 4 prompts, 189.080 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv  get_availabl: prompt cache update took 7.29 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 120 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.895 (> 0.100 thold), f_keep = 0.631
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 121 | processing task, is_child = 0
slot update_slots: id  1 | task 119 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 87
slot update_slots: id  1 | task 119 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 119 | prompt processing progress, n_tokens = 87, batch.n_tokens = 11, progress = 1.000000
slot update_slots: id  1 | task 119 | prompt done, n_tokens = 87, batch.n_tokens = 11
slot init_sampler: id  1 | task 119 | init sampler, took 0.01 ms, tokens: text = 87, total = 87
slot update_slots: id  2 | task 120 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  2 | task 120 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 120 | prompt processing progress, n_tokens = 81, batch.n_tokens = 15, progress = 1.000000
slot update_slots: id  2 | task 120 | prompt done, n_tokens = 81, batch.n_tokens = 15
slot init_sampler: id  2 | task 120 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot update_slots: id  3 | task 121 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 86
slot update_slots: id  3 | task 121 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 121 | prompt processing progress, n_tokens = 86, batch.n_tokens = 24, progress = 1.000000
slot update_slots: id  3 | task 121 | prompt done, n_tokens = 86, batch.n_tokens = 24
slot init_sampler: id  3 | task 121 | init sampler, took 0.01 ms, tokens: text = 86, total = 86
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 117 | 
prompt eval time =     421.24 ms /     3 tokens (  140.41 ms per token,     7.12 tokens per second)
       eval time =    3176.29 ms /    11 tokens (  288.75 ms per token,     3.46 tokens per second)
      total time =    3597.53 ms /    14 tokens
slot      release: id  0 | task 117 | stop processing: n_tokens = 90, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.865 (> 0.100 thold), f_keep = 0.856
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 122 | processing task, is_child = 0
slot update_slots: id  0 | task 122 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 89
slot update_slots: id  0 | task 122 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 122 | prompt processing progress, n_tokens = 89, batch.n_tokens = 15, progress = 1.000000
slot update_slots: id  0 | task 122 | prompt done, n_tokens = 89, batch.n_tokens = 15
slot init_sampler: id  0 | task 122 | init sampler, took 0.01 ms, tokens: text = 89, total = 89
slot print_timing: id  2 | task 120 | 
prompt eval time =     352.72 ms /     4 tokens (   88.18 ms per token,    11.34 tokens per second)
       eval time =    3162.21 ms /    11 tokens (  287.47 ms per token,     3.48 tokens per second)
      total time =    3514.92 ms /    15 tokens
slot      release: id  2 | task 120 | stop processing: n_tokens = 91, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 124 | processing task, is_child = 0
slot update_slots: id  2 | task 124 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  2 | task 124 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 124 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  2 | task 124 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  2 | task 124 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot print_timing: id  3 | task 121 | 
prompt eval time =     359.73 ms /     9 tokens (   39.97 ms per token,    25.02 tokens per second)
       eval time =    3676.39 ms /    12 tokens (  306.37 ms per token,     3.26 tokens per second)
      total time =    4036.12 ms /    21 tokens
slot      release: id  3 | task 121 | stop processing: n_tokens = 97, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  1 | task 119 | 
prompt eval time =     352.33 ms /    10 tokens (   35.23 ms per token,    28.38 tokens per second)
       eval time =    4071.79 ms /    14 tokens (  290.84 ms per token,     3.44 tokens per second)
      total time =    4424.12 ms /    24 tokens
slot      release: id  1 | task 119 | stop processing: n_tokens = 100, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  0 | task 122 | 
prompt eval time =     345.19 ms /    12 tokens (   28.77 ms per token,    34.76 tokens per second)
       eval time =    1713.51 ms /    10 tokens (  171.35 ms per token,     5.84 tokens per second)
      total time =    2058.70 ms /    22 tokens
slot      release: id  0 | task 122 | stop processing: n_tokens = 98, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 124 | 
prompt eval time =     520.89 ms /     4 tokens (  130.22 ms per token,     7.68 tokens per second)
       eval time =    1421.53 ms /    11 tokens (  129.23 ms per token,     7.74 tokens per second)
      total time =    1942.42 ms /    15 tokens
slot      release: id  2 | task 124 | stop processing: n_tokens = 91, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.786
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 146 | processing task, is_child = 0
slot update_slots: id  0 | task 146 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  0 | task 146 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 146 | prompt processing progress, n_tokens = 84, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  0 | task 146 | prompt done, n_tokens = 84, batch.n_tokens = 7
slot init_sampler: id  0 | task 146 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.770
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 148 | processing task, is_child = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.802 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 149 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.688 (> 0.100 thold), f_keep = 0.794
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 150 | processing task, is_child = 0
slot update_slots: id  1 | task 148 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  1 | task 148 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 148 | prompt processing progress, n_tokens = 84, batch.n_tokens = 8, progress = 1.000000
slot update_slots: id  1 | task 148 | prompt done, n_tokens = 84, batch.n_tokens = 8
slot init_sampler: id  1 | task 148 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
slot update_slots: id  2 | task 149 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 96
slot update_slots: id  2 | task 149 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 149 | prompt processing progress, n_tokens = 96, batch.n_tokens = 27, progress = 1.000000
slot update_slots: id  2 | task 149 | prompt done, n_tokens = 96, batch.n_tokens = 27
slot init_sampler: id  2 | task 149 | init sampler, took 0.01 ms, tokens: text = 96, total = 96
slot update_slots: id  3 | task 150 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 112
slot update_slots: id  3 | task 150 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 150 | prompt processing progress, n_tokens = 112, batch.n_tokens = 62, progress = 1.000000
slot update_slots: id  3 | task 150 | prompt done, n_tokens = 112, batch.n_tokens = 62
slot init_sampler: id  3 | task 150 | init sampler, took 0.01 ms, tokens: text = 112, total = 112
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 146 | 
prompt eval time =     506.84 ms /     7 tokens (   72.41 ms per token,    13.81 tokens per second)
       eval time =    3863.10 ms /    11 tokens (  351.19 ms per token,     2.85 tokens per second)
      total time =    4369.93 ms /    18 tokens
slot      release: id  0 | task 146 | stop processing: n_tokens = 94, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  1 | task 148 | 
prompt eval time =     615.85 ms /     7 tokens (   87.98 ms per token,    11.37 tokens per second)
       eval time =    3247.41 ms /    10 tokens (  324.74 ms per token,     3.08 tokens per second)
      total time =    3863.26 ms /    17 tokens
slot      release: id  1 | task 148 | stop processing: n_tokens = 93, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.726 (> 0.100 thold), f_keep = 0.819
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 152 | processing task, is_child = 0
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.401 (> 0.100 thold), f_keep = 0.828
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 151 | processing task, is_child = 0
slot update_slots: id  0 | task 152 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 106
slot update_slots: id  0 | task 152 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 152 | prompt processing progress, n_tokens = 106, batch.n_tokens = 31, progress = 1.000000
slot update_slots: id  0 | task 152 | prompt done, n_tokens = 106, batch.n_tokens = 31
slot init_sampler: id  0 | task 152 | init sampler, took 0.01 ms, tokens: text = 106, total = 106
slot update_slots: id  1 | task 151 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 192
slot update_slots: id  1 | task 151 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 151 | prompt processing progress, n_tokens = 192, batch.n_tokens = 146, progress = 1.000000
slot update_slots: id  1 | task 151 | prompt done, n_tokens = 192, batch.n_tokens = 146
slot init_sampler: id  1 | task 151 | init sampler, took 0.02 ms, tokens: text = 192, total = 192
slot print_timing: id  3 | task 150 | 
prompt eval time =     629.74 ms /    35 tokens (   17.99 ms per token,    55.58 tokens per second)
       eval time =    4739.81 ms /    11 tokens (  430.89 ms per token,     2.32 tokens per second)
      total time =    5369.55 ms /    46 tokens
slot      release: id  3 | task 150 | stop processing: n_tokens = 122, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.786 (> 0.100 thold), f_keep = 0.631
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 154 | processing task, is_child = 0
slot update_slots: id  3 | task 154 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 98
slot update_slots: id  3 | task 154 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 154 | prompt processing progress, n_tokens = 98, batch.n_tokens = 24, progress = 1.000000
slot update_slots: id  3 | task 154 | prompt done, n_tokens = 98, batch.n_tokens = 24
slot init_sampler: id  3 | task 154 | init sampler, took 0.01 ms, tokens: text = 98, total = 98
slot print_timing: id  2 | task 149 | 
prompt eval time =     622.83 ms /    19 tokens (   32.78 ms per token,    30.51 tokens per second)
       eval time =    6505.89 ms /    14 tokens (  464.71 ms per token,     2.15 tokens per second)
      total time =    7128.72 ms /    33 tokens
slot      release: id  2 | task 149 | stop processing: n_tokens = 109, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.706
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 155 | processing task, is_child = 0
slot update_slots: id  2 | task 155 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 80
slot update_slots: id  2 | task 155 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 155 | prompt processing progress, n_tokens = 80, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  2 | task 155 | prompt done, n_tokens = 80, batch.n_tokens = 6
slot init_sampler: id  2 | task 155 | init sampler, took 0.01 ms, tokens: text = 80, total = 80
slot print_timing: id  0 | task 152 | 
prompt eval time =    1498.63 ms /    29 tokens (   51.68 ms per token,    19.35 tokens per second)
       eval time =    4398.85 ms /    11 tokens (  399.90 ms per token,     2.50 tokens per second)
      total time =    5897.47 ms /    40 tokens
slot      release: id  0 | task 152 | stop processing: n_tokens = 116, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 154 | 
prompt eval time =     618.81 ms /    21 tokens (   29.47 ms per token,    33.94 tokens per second)
       eval time =    3773.21 ms /    10 tokens (  377.32 ms per token,     2.65 tokens per second)
      total time =    4392.02 ms /    31 tokens
slot      release: id  3 | task 154 | stop processing: n_tokens = 107, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  1 | task 151 | 
prompt eval time =    1505.51 ms /   115 tokens (   13.09 ms per token,    76.39 tokens per second)
       eval time =    5036.64 ms /    14 tokens (  359.76 ms per token,     2.78 tokens per second)
      total time =    6542.14 ms /   129 tokens
slot      release: id  1 | task 151 | stop processing: n_tokens = 205, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 155 | 
prompt eval time =     422.45 ms /     3 tokens (  140.82 ms per token,     7.10 tokens per second)
       eval time =    2854.75 ms /    10 tokens (  285.47 ms per token,     3.50 tokens per second)
      total time =    3277.20 ms /    13 tokens
slot      release: id  2 | task 155 | stop processing: n_tokens = 89, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LRU, t_last = 1029204550378
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 116, total state size = 18.127 MiB
srv          load:  - looking for better prompt, base f_keep = 0.664, sim = 0.079
srv        update:  - cache state: 5 prompts, 207.207 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv  get_availabl: prompt cache update took 7.37 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 179 | processing task, is_child = 0
slot update_slots: id  0 | task 179 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 973
slot update_slots: id  0 | task 179 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 179 | prompt processing progress, n_tokens = 973, batch.n_tokens = 896, progress = 1.000000
slot update_slots: id  0 | task 179 | prompt done, n_tokens = 973, batch.n_tokens = 896
slot init_sampler: id  0 | task 179 | init sampler, took 0.11 ms, tokens: text = 973, total = 973
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.733 (> 0.100 thold), f_keep = 0.376
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 205, total state size = 32.035 MiB
srv          load:  - looking for better prompt, base f_keep = 0.376, sim = 0.733
srv        update:  - cache state: 6 prompts, 239.242 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv  get_availabl: prompt cache update took 6.59 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 181 | processing task, is_child = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.875 (> 0.100 thold), f_keep = 0.865
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 182 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.410 (> 0.100 thold), f_keep = 0.720
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 183 | processing task, is_child = 0
slot update_slots: id  1 | task 181 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 105
slot update_slots: id  1 | task 181 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 181 | prompt processing progress, n_tokens = 105, batch.n_tokens = 29, progress = 1.000000
slot update_slots: id  1 | task 181 | prompt done, n_tokens = 105, batch.n_tokens = 29
slot init_sampler: id  1 | task 181 | init sampler, took 0.01 ms, tokens: text = 105, total = 105
slot update_slots: id  2 | task 182 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 88
slot update_slots: id  2 | task 182 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 182 | prompt processing progress, n_tokens = 88, batch.n_tokens = 40, progress = 1.000000
slot update_slots: id  2 | task 182 | prompt done, n_tokens = 88, batch.n_tokens = 40
slot init_sampler: id  2 | task 182 | init sampler, took 0.01 ms, tokens: text = 88, total = 88
slot update_slots: id  3 | task 183 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 188
slot update_slots: id  3 | task 183 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 183 | prompt processing progress, n_tokens = 188, batch.n_tokens = 151, progress = 1.000000
slot update_slots: id  3 | task 183 | prompt done, n_tokens = 188, batch.n_tokens = 151
slot init_sampler: id  3 | task 183 | init sampler, took 0.02 ms, tokens: text = 188, total = 188
slot print_timing: id  0 | task 179 | 
prompt eval time =    8369.85 ms /   896 tokens (    9.34 ms per token,   107.05 tokens per second)
       eval time =    4554.51 ms /    11 tokens (  414.05 ms per token,     2.42 tokens per second)
      total time =   12924.36 ms /   907 tokens
slot      release: id  0 | task 179 | stop processing: n_tokens = 983, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 183 | 
prompt eval time =    1729.56 ms /   111 tokens (   15.58 ms per token,    64.18 tokens per second)
       eval time =    2818.62 ms /    10 tokens (  281.86 ms per token,     3.55 tokens per second)
      total time =    4548.18 ms /   121 tokens
slot      release: id  3 | task 183 | stop processing: n_tokens = 197, truncated = 0
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.379 (> 0.100 thold), f_keep = 0.078
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 983, total state size = 153.606 MiB
srv  params_from_: Chat format: Content-only
srv          load:  - looking for better prompt, base f_keep = 0.078, sim = 0.379
srv        update:  - cache state: 7 prompts, 392.848 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv  get_availabl: prompt cache update took 23.45 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 185 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.770 (> 0.100 thold), f_keep = 0.391
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 197, total state size = 30.784 MiB
srv          load:  - looking for better prompt, base f_keep = 0.391, sim = 0.770
srv        update:  - cache state: 8 prompts, 423.632 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv  get_availabl: prompt cache update took 11.42 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 184 | processing task, is_child = 0
slot update_slots: id  0 | task 185 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 203
slot update_slots: id  0 | task 185 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 185 | prompt processing progress, n_tokens = 203, batch.n_tokens = 128, progress = 1.000000
slot update_slots: id  0 | task 185 | prompt done, n_tokens = 203, batch.n_tokens = 128
slot init_sampler: id  0 | task 185 | init sampler, took 0.02 ms, tokens: text = 203, total = 203
slot update_slots: id  3 | task 184 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 100
slot update_slots: id  3 | task 184 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 184 | prompt processing progress, n_tokens = 100, batch.n_tokens = 151, progress = 1.000000
slot update_slots: id  3 | task 184 | prompt done, n_tokens = 100, batch.n_tokens = 151
slot init_sampler: id  3 | task 184 | init sampler, took 0.01 ms, tokens: text = 100, total = 100
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 182 | 
prompt eval time =    1722.82 ms /    11 tokens (  156.62 ms per token,     6.38 tokens per second)
       eval time =    4830.53 ms /    12 tokens (  402.54 ms per token,     2.48 tokens per second)
      total time =    6553.35 ms /    23 tokens
slot      release: id  2 | task 182 | stop processing: n_tokens = 99, truncated = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.778
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 186 | processing task, is_child = 0
slot update_slots: id  2 | task 186 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 79
slot update_slots: id  2 | task 186 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 186 | prompt processing progress, n_tokens = 79, batch.n_tokens = 5, progress = 1.000000
slot update_slots: id  2 | task 186 | prompt done, n_tokens = 79, batch.n_tokens = 5
slot init_sampler: id  2 | task 186 | init sampler, took 0.01 ms, tokens: text = 79, total = 79
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 181 | 
prompt eval time =    1715.97 ms /    28 tokens (   61.28 ms per token,    16.32 tokens per second)
       eval time =    5760.33 ms /    14 tokens (  411.45 ms per token,     2.43 tokens per second)
      total time =    7476.29 ms /    42 tokens
slot      release: id  1 | task 181 | stop processing: n_tokens = 118, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.281 (> 0.100 thold), f_keep = 0.653
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 187 | processing task, is_child = 0
slot update_slots: id  1 | task 187 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 274
slot update_slots: id  1 | task 187 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 187 | prompt processing progress, n_tokens = 274, batch.n_tokens = 200, progress = 1.000000
slot update_slots: id  1 | task 187 | prompt done, n_tokens = 274, batch.n_tokens = 200
slot init_sampler: id  1 | task 187 | init sampler, took 0.03 ms, tokens: text = 274, total = 274
slot print_timing: id  0 | task 185 | 
prompt eval time =    1483.06 ms /   126 tokens (   11.77 ms per token,    84.96 tokens per second)
       eval time =    5108.60 ms /     9 tokens (  567.62 ms per token,     1.76 tokens per second)
      total time =    6591.66 ms /   135 tokens
slot      release: id  0 | task 185 | stop processing: n_tokens = 211, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.897 (> 0.100 thold), f_keep = 0.370
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 211, total state size = 32.972 MiB
srv          load:  - looking for better prompt, base f_keep = 0.370, sim = 0.897
srv        update:  - cache state: 9 prompts, 456.604 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4e10:     211 tokens, checkpoints:  0,    32.972 MiB
srv  get_availabl: prompt cache update took 5.33 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 188 | processing task, is_child = 0
slot update_slots: id  0 | task 188 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 87
slot update_slots: id  0 | task 188 | n_tokens = 78, memory_seq_rm [78, end)
slot update_slots: id  0 | task 188 | prompt processing progress, n_tokens = 87, batch.n_tokens = 12, progress = 1.000000
slot update_slots: id  0 | task 188 | prompt done, n_tokens = 87, batch.n_tokens = 12
slot init_sampler: id  0 | task 188 | init sampler, took 0.01 ms, tokens: text = 87, total = 87
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 186 | 
prompt eval time =     401.41 ms /     2 tokens (  200.71 ms per token,     4.98 tokens per second)
       eval time =    5678.48 ms /    11 tokens (  516.23 ms per token,     1.94 tokens per second)
      total time =    6079.89 ms /    13 tokens
slot      release: id  2 | task 186 | stop processing: n_tokens = 89, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.885 (> 0.100 thold), f_keep = 0.865
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 189 | processing task, is_child = 0
slot update_slots: id  2 | task 189 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 87
slot update_slots: id  2 | task 189 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 189 | prompt processing progress, n_tokens = 87, batch.n_tokens = 13, progress = 1.000000
slot update_slots: id  2 | task 189 | prompt done, n_tokens = 87, batch.n_tokens = 13
slot init_sampler: id  2 | task 189 | init sampler, took 0.01 ms, tokens: text = 87, total = 87
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 187 | 
prompt eval time =    2284.68 ms /   197 tokens (   11.60 ms per token,    86.23 tokens per second)
       eval time =    3195.97 ms /    10 tokens (  319.60 ms per token,     3.13 tokens per second)
      total time =    5480.65 ms /   207 tokens
slot      release: id  1 | task 187 | stop processing: n_tokens = 283, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 184 | 
prompt eval time =    1489.52 ms /    23 tokens (   64.76 ms per token,    15.44 tokens per second)
       eval time =    6898.15 ms /    14 tokens (  492.73 ms per token,     2.03 tokens per second)
      total time =    8387.67 ms /    37 tokens
slot      release: id  3 | task 184 | stop processing: n_tokens = 113, truncated = 0
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.778 (> 0.100 thold), f_keep = 0.272
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 283, total state size = 44.223 MiB
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv          load:  - looking for better prompt, base f_keep = 0.272, sim = 0.778
srv          load:  - found better prompt with f_keep = 0.370, sim = 0.788
srv  params_from_: Chat format: Content-only
srv        update:  - cache state: 9 prompts, 467.855 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv  get_availabl: prompt cache update took 22.49 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 202 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.688 (> 0.100 thold), f_keep = 0.681
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 200 | processing task, is_child = 0
slot update_slots: id  1 | task 202 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 99
slot update_slots: id  1 | task 202 | n_tokens = 78, memory_seq_rm [78, end)
slot update_slots: id  1 | task 202 | prompt processing progress, n_tokens = 99, batch.n_tokens = 23, progress = 1.000000
slot update_slots: id  1 | task 202 | prompt done, n_tokens = 99, batch.n_tokens = 23
slot init_sampler: id  1 | task 202 | init sampler, took 0.01 ms, tokens: text = 99, total = 99
slot update_slots: id  3 | task 200 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 112
slot update_slots: id  3 | task 200 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 200 | prompt processing progress, n_tokens = 112, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  3 | task 200 | prompt done, n_tokens = 112, batch.n_tokens = 58
slot init_sampler: id  3 | task 200 | init sampler, took 0.01 ms, tokens: text = 112, total = 112
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 188 | 
prompt eval time =     376.20 ms /     9 tokens (   41.80 ms per token,    23.92 tokens per second)
       eval time =    4363.76 ms /    14 tokens (  311.70 ms per token,     3.21 tokens per second)
      total time =    4739.96 ms /    23 tokens
slot      release: id  0 | task 188 | stop processing: n_tokens = 100, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.770
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 205 | processing task, is_child = 0
slot update_slots: id  0 | task 205 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  0 | task 205 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 205 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  0 | task 205 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  0 | task 205 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 189 | 
prompt eval time =     337.99 ms /    10 tokens (   33.80 ms per token,    29.59 tokens per second)
       eval time =    4044.43 ms /    13 tokens (  311.11 ms per token,     3.21 tokens per second)
      total time =    4382.41 ms /    23 tokens
slot      release: id  2 | task 189 | stop processing: n_tokens = 99, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.647 (> 0.100 thold), f_keep = 0.778
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 207 | processing task, is_child = 0
slot update_slots: id  2 | task 207 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 119
slot update_slots: id  2 | task 207 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 207 | prompt processing progress, n_tokens = 119, batch.n_tokens = 45, progress = 1.000000
slot update_slots: id  2 | task 207 | prompt done, n_tokens = 119, batch.n_tokens = 45
slot init_sampler: id  2 | task 207 | init sampler, took 0.01 ms, tokens: text = 119, total = 119
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 200 | 
prompt eval time =     613.44 ms /    35 tokens (   17.53 ms per token,    57.06 tokens per second)
       eval time =    4014.15 ms /    13 tokens (  308.78 ms per token,     3.24 tokens per second)
      total time =    4627.59 ms /    48 tokens
slot      release: id  3 | task 200 | stop processing: n_tokens = 124, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.448 (> 0.100 thold), f_keep = 0.621
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 214 | processing task, is_child = 0
slot update_slots: id  3 | task 214 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 172
slot update_slots: id  3 | task 214 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 214 | prompt processing progress, n_tokens = 172, batch.n_tokens = 98, progress = 1.000000
slot update_slots: id  3 | task 214 | prompt done, n_tokens = 172, batch.n_tokens = 98
slot init_sampler: id  3 | task 214 | init sampler, took 0.01 ms, tokens: text = 172, total = 172
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 202 | 
prompt eval time =     604.68 ms /    21 tokens (   28.79 ms per token,    34.73 tokens per second)
       eval time =    5181.33 ms /    14 tokens (  370.09 ms per token,     2.70 tokens per second)
      total time =    5786.01 ms /    35 tokens
slot      release: id  1 | task 202 | stop processing: n_tokens = 112, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.755 (> 0.100 thold), f_keep = 0.688
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 219 | processing task, is_child = 0
slot update_slots: id  1 | task 219 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 102
slot update_slots: id  1 | task 219 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 219 | prompt processing progress, n_tokens = 102, batch.n_tokens = 28, progress = 1.000000
slot update_slots: id  1 | task 219 | prompt done, n_tokens = 102, batch.n_tokens = 28
slot init_sampler: id  1 | task 219 | init sampler, took 0.01 ms, tokens: text = 102, total = 102
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 205 | 
prompt eval time =     513.20 ms /     4 tokens (  128.30 ms per token,     7.79 tokens per second)
       eval time =    4736.95 ms /    13 tokens (  364.38 ms per token,     2.74 tokens per second)
      total time =    5250.15 ms /    17 tokens
slot      release: id  0 | task 205 | stop processing: n_tokens = 93, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 207 | 
prompt eval time =     605.74 ms /    42 tokens (   14.42 ms per token,    69.34 tokens per second)
       eval time =    3550.65 ms /    10 tokens (  355.06 ms per token,     2.82 tokens per second)
      total time =    4156.39 ms /    52 tokens
slot      release: id  2 | task 207 | stop processing: n_tokens = 128, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.828
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 222 | processing task, is_child = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.794 (> 0.100 thold), f_keep = 0.602
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 220 | processing task, is_child = 0
slot update_slots: id  0 | task 222 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  0 | task 222 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 222 | prompt processing progress, n_tokens = 81, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  0 | task 222 | prompt done, n_tokens = 81, batch.n_tokens = 6
slot init_sampler: id  0 | task 222 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot update_slots: id  2 | task 220 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 97
slot update_slots: id  2 | task 220 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 220 | prompt processing progress, n_tokens = 97, batch.n_tokens = 26, progress = 1.000000
slot update_slots: id  2 | task 220 | prompt done, n_tokens = 97, batch.n_tokens = 26
slot init_sampler: id  2 | task 220 | init sampler, took 0.01 ms, tokens: text = 97, total = 97
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 219 | 
prompt eval time =     345.23 ms /    25 tokens (   13.81 ms per token,    72.42 tokens per second)
       eval time =    3850.45 ms /    14 tokens (  275.03 ms per token,     3.64 tokens per second)
      total time =    4195.67 ms /    39 tokens
slot      release: id  1 | task 219 | stop processing: n_tokens = 115, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 214 | 
prompt eval time =    1165.55 ms /    95 tokens (   12.27 ms per token,    81.51 tokens per second)
       eval time =    4196.10 ms /    15 tokens (  279.74 ms per token,     3.57 tokens per second)
      total time =    5361.65 ms /   110 tokens
slot      release: id  3 | task 214 | stop processing: n_tokens = 186, truncated = 0
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.895 (> 0.100 thold), f_keep = 0.670
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 236 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.336 (> 0.100 thold), f_keep = 0.414
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 186, total state size = 29.066 MiB
srv  params_from_: Chat format: Content-only
srv          load:  - looking for better prompt, base f_keep = 0.414, sim = 0.336
srv        update:  - cache state: 10 prompts, 496.921 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv  get_availabl: prompt cache update took 20.75 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 232 | processing task, is_child = 0
slot update_slots: id  1 | task 236 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 86
slot update_slots: id  1 | task 236 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 236 | prompt processing progress, n_tokens = 86, batch.n_tokens = 11, progress = 1.000000
slot update_slots: id  1 | task 236 | prompt done, n_tokens = 86, batch.n_tokens = 11
slot init_sampler: id  1 | task 236 | init sampler, took 0.01 ms, tokens: text = 86, total = 86
slot update_slots: id  3 | task 232 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 229
slot update_slots: id  3 | task 232 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 232 | prompt processing progress, n_tokens = 229, batch.n_tokens = 163, progress = 1.000000
slot update_slots: id  3 | task 232 | prompt done, n_tokens = 229, batch.n_tokens = 163
slot init_sampler: id  3 | task 232 | init sampler, took 0.02 ms, tokens: text = 229, total = 229
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 220 | 
prompt eval time =     351.60 ms /    20 tokens (   17.58 ms per token,    56.88 tokens per second)
       eval time =    4354.96 ms /    11 tokens (  395.91 ms per token,     2.53 tokens per second)
      total time =    4706.56 ms /    31 tokens
slot      release: id  2 | task 220 | stop processing: n_tokens = 107, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.602 (> 0.100 thold), f_keep = 0.720
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 238 | processing task, is_child = 0
slot update_slots: id  2 | task 238 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 128
slot update_slots: id  2 | task 238 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 238 | prompt processing progress, n_tokens = 128, batch.n_tokens = 54, progress = 1.000000
slot update_slots: id  2 | task 238 | prompt done, n_tokens = 128, batch.n_tokens = 54
slot init_sampler: id  2 | task 238 | init sampler, took 0.01 ms, tokens: text = 128, total = 128
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 222 | 
prompt eval time =     344.79 ms /     4 tokens (   86.20 ms per token,    11.60 tokens per second)
       eval time =    5262.46 ms /    13 tokens (  404.80 ms per token,     2.47 tokens per second)
      total time =    5607.25 ms /    17 tokens
slot      release: id  0 | task 222 | stop processing: n_tokens = 93, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.828
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 240 | processing task, is_child = 0
slot update_slots: id  0 | task 240 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  0 | task 240 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 240 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  0 | task 240 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  0 | task 240 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
slot print_timing: id  1 | task 236 | 
prompt eval time =    1709.53 ms /     9 tokens (  189.95 ms per token,     5.26 tokens per second)
       eval time =    3471.59 ms /    11 tokens (  315.60 ms per token,     3.17 tokens per second)
      total time =    5181.12 ms /    20 tokens
slot      release: id  1 | task 236 | stop processing: n_tokens = 96, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.802
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 249 | processing task, is_child = 0
slot update_slots: id  1 | task 249 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  1 | task 249 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 249 | prompt processing progress, n_tokens = 84, batch.n_tokens = 10, progress = 1.000000
slot update_slots: id  1 | task 249 | prompt done, n_tokens = 84, batch.n_tokens = 10
slot init_sampler: id  1 | task 249 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 232 | 
prompt eval time =    1716.34 ms /   152 tokens (   11.29 ms per token,    88.56 tokens per second)
       eval time =    4393.40 ms /    14 tokens (  313.81 ms per token,     3.19 tokens per second)
      total time =    6109.75 ms /   166 tokens
slot      release: id  3 | task 232 | stop processing: n_tokens = 242, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.748 (> 0.100 thold), f_keep = 0.318
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 242, total state size = 37.816 MiB
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv          load:  - looking for better prompt, base f_keep = 0.318, sim = 0.748
srv        update:  - cache state: 11 prompts, 534.737 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv  get_availabl: prompt cache update took 8.51 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 250 | processing task, is_child = 0
slot update_slots: id  3 | task 250 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 103
slot update_slots: id  3 | task 250 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 250 | prompt processing progress, n_tokens = 103, batch.n_tokens = 29, progress = 1.000000
slot update_slots: id  3 | task 250 | prompt done, n_tokens = 103, batch.n_tokens = 29
slot init_sampler: id  3 | task 250 | init sampler, took 0.01 ms, tokens: text = 103, total = 103
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 238 | 
prompt eval time =     607.40 ms /    51 tokens (   11.91 ms per token,    83.96 tokens per second)
       eval time =    2975.55 ms /    10 tokens (  297.55 ms per token,     3.36 tokens per second)
      total time =    3582.95 ms /    61 tokens
slot      release: id  2 | task 238 | stop processing: n_tokens = 137, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.819 (> 0.100 thold), f_keep = 0.562
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 256 | processing task, is_child = 0
slot update_slots: id  2 | task 256 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 94
slot update_slots: id  2 | task 256 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 256 | prompt processing progress, n_tokens = 94, batch.n_tokens = 20, progress = 1.000000
slot update_slots: id  2 | task 256 | prompt done, n_tokens = 94, batch.n_tokens = 20
slot init_sampler: id  2 | task 256 | init sampler, took 0.01 ms, tokens: text = 94, total = 94
slot print_timing: id  0 | task 240 | 
prompt eval time =     513.60 ms /     4 tokens (  128.40 ms per token,     7.79 tokens per second)
       eval time =    2797.10 ms /    10 tokens (  279.71 ms per token,     3.58 tokens per second)
      total time =    3310.70 ms /    14 tokens
slot      release: id  0 | task 240 | stop processing: n_tokens = 90, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.748 (> 0.100 thold), f_keep = 0.856
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 258 | processing task, is_child = 0
slot update_slots: id  0 | task 258 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 103
slot update_slots: id  0 | task 258 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 258 | prompt processing progress, n_tokens = 103, batch.n_tokens = 29, progress = 1.000000
slot update_slots: id  0 | task 258 | prompt done, n_tokens = 103, batch.n_tokens = 29
slot init_sampler: id  0 | task 258 | init sampler, took 0.01 ms, tokens: text = 103, total = 103
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 249 | 
prompt eval time =     346.82 ms /     7 tokens (   49.55 ms per token,    20.18 tokens per second)
       eval time =    3076.80 ms /    11 tokens (  279.71 ms per token,     3.58 tokens per second)
      total time =    3423.62 ms /    18 tokens
slot      release: id  1 | task 249 | stop processing: n_tokens = 94, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.688 (> 0.100 thold), f_keep = 0.819
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 264 | processing task, is_child = 0
slot update_slots: id  1 | task 264 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 112
slot update_slots: id  1 | task 264 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 264 | prompt processing progress, n_tokens = 112, batch.n_tokens = 38, progress = 1.000000
slot update_slots: id  1 | task 264 | prompt done, n_tokens = 112, batch.n_tokens = 38
slot init_sampler: id  1 | task 264 | init sampler, took 0.01 ms, tokens: text = 112, total = 112
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 250 | 
prompt eval time =     346.41 ms /    26 tokens (   13.32 ms per token,    75.05 tokens per second)
       eval time =    4093.04 ms /    13 tokens (  314.85 ms per token,     3.18 tokens per second)
      total time =    4439.46 ms /    39 tokens
slot      release: id  3 | task 250 | stop processing: n_tokens = 115, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.670
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 266 | processing task, is_child = 0
slot update_slots: id  3 | task 266 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  3 | task 266 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 266 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  3 | task 266 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  3 | task 266 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 256 | 
prompt eval time =     342.51 ms /    17 tokens (   20.15 ms per token,    49.63 tokens per second)
       eval time =    4551.78 ms /    14 tokens (  325.13 ms per token,     3.08 tokens per second)
      total time =    4894.29 ms /    31 tokens
slot      release: id  2 | task 256 | stop processing: n_tokens = 107, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.720
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 272 | processing task, is_child = 0
slot update_slots: id  2 | task 272 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  2 | task 272 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 272 | prompt processing progress, n_tokens = 84, batch.n_tokens = 10, progress = 1.000000
slot update_slots: id  2 | task 272 | prompt done, n_tokens = 84, batch.n_tokens = 10
slot init_sampler: id  2 | task 272 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 258 | 
prompt eval time =     345.35 ms /    26 tokens (   13.28 ms per token,    75.29 tokens per second)
       eval time =    4555.66 ms /    14 tokens (  325.40 ms per token,     3.07 tokens per second)
      total time =    4901.01 ms /    40 tokens
slot      release: id  0 | task 258 | stop processing: n_tokens = 116, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.524 (> 0.100 thold), f_keep = 0.664
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 276 | processing task, is_child = 0
slot update_slots: id  0 | task 276 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 147
slot update_slots: id  0 | task 276 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 276 | prompt processing progress, n_tokens = 147, batch.n_tokens = 73, progress = 1.000000
slot update_slots: id  0 | task 276 | prompt done, n_tokens = 147, batch.n_tokens = 73
slot init_sampler: id  0 | task 276 | init sampler, took 0.02 ms, tokens: text = 147, total = 147
slot print_timing: id  1 | task 264 | 
prompt eval time =     619.59 ms /    35 tokens (   17.70 ms per token,    56.49 tokens per second)
       eval time =    3970.09 ms /    11 tokens (  360.92 ms per token,     2.77 tokens per second)
      total time =    4589.68 ms /    46 tokens
slot      release: id  1 | task 264 | stop processing: n_tokens = 122, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.438 (> 0.100 thold), f_keep = 0.631
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 277 | processing task, is_child = 0
slot update_slots: id  1 | task 277 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 176
slot update_slots: id  1 | task 277 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 277 | prompt processing progress, n_tokens = 176, batch.n_tokens = 102, progress = 1.000000
slot update_slots: id  1 | task 277 | prompt done, n_tokens = 176, batch.n_tokens = 102
slot init_sampler: id  1 | task 277 | init sampler, took 0.02 ms, tokens: text = 176, total = 176
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 266 | 
prompt eval time =     514.15 ms /     4 tokens (  128.54 ms per token,     7.78 tokens per second)
       eval time =    4497.57 ms /    11 tokens (  408.87 ms per token,     2.45 tokens per second)
      total time =    5011.72 ms /    15 tokens
slot      release: id  3 | task 266 | stop processing: n_tokens = 91, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.374 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 281 | processing task, is_child = 0
slot update_slots: id  3 | task 281 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 206
slot update_slots: id  3 | task 281 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 281 | prompt processing progress, n_tokens = 206, batch.n_tokens = 132, progress = 1.000000
slot update_slots: id  3 | task 281 | prompt done, n_tokens = 206, batch.n_tokens = 132
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot init_sampler: id  3 | task 281 | init sampler, took 0.02 ms, tokens: text = 206, total = 206
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 272 | 
prompt eval time =     342.06 ms /     7 tokens (   48.87 ms per token,    20.46 tokens per second)
       eval time =    5314.91 ms /    10 tokens (  531.49 ms per token,     1.88 tokens per second)
      total time =    5656.97 ms /    17 tokens
slot      release: id  2 | task 272 | stop processing: n_tokens = 93, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.475 (> 0.100 thold), f_keep = 0.828
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 287 | processing task, is_child = 0
slot update_slots: id  2 | task 287 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 162
slot update_slots: id  2 | task 287 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 287 | prompt processing progress, n_tokens = 162, batch.n_tokens = 88, progress = 1.000000
slot update_slots: id  2 | task 287 | prompt done, n_tokens = 162, batch.n_tokens = 88
slot init_sampler: id  2 | task 287 | init sampler, took 0.02 ms, tokens: text = 162, total = 162
slot print_timing: id  0 | task 276 | 
prompt eval time =     893.48 ms /    70 tokens (   12.76 ms per token,    78.35 tokens per second)
       eval time =    5322.79 ms /    10 tokens (  532.28 ms per token,     1.88 tokens per second)
      total time =    6216.27 ms /    80 tokens
slot      release: id  0 | task 276 | stop processing: n_tokens = 156, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.546 (> 0.100 thold), f_keep = 0.494
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 156, total state size = 24.378 MiB
srv          load:  - looking for better prompt, base f_keep = 0.494, sim = 0.546
srv        update:  - cache state: 12 prompts, 559.115 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv  get_availabl: prompt cache update took 4.16 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 293 | processing task, is_child = 0
slot update_slots: id  0 | task 293 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 141
slot update_slots: id  0 | task 293 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 293 | prompt processing progress, n_tokens = 141, batch.n_tokens = 67, progress = 1.000000
slot update_slots: id  0 | task 293 | prompt done, n_tokens = 141, batch.n_tokens = 67
slot init_sampler: id  0 | task 293 | init sampler, took 0.02 ms, tokens: text = 141, total = 141
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 277 | 
prompt eval time =    1179.41 ms /    99 tokens (   11.91 ms per token,    83.94 tokens per second)
       eval time =    6188.85 ms /    14 tokens (  442.06 ms per token,     2.26 tokens per second)
      total time =    7368.26 ms /   113 tokens
slot      release: id  1 | task 277 | stop processing: n_tokens = 189, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.407
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 189, total state size = 29.534 MiB
srv          load:  - looking for better prompt, base f_keep = 0.407, sim = 0.962
srv        update:  - cache state: 13 prompts, 588.649 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv  get_availabl: prompt cache update took 3.83 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 296 | processing task, is_child = 0
slot update_slots: id  1 | task 296 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 80
slot update_slots: id  1 | task 296 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 296 | prompt processing progress, n_tokens = 80, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  1 | task 296 | prompt done, n_tokens = 80, batch.n_tokens = 6
slot init_sampler: id  1 | task 296 | init sampler, took 0.01 ms, tokens: text = 80, total = 80
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 281 | 
prompt eval time =    1460.89 ms /   129 tokens (   11.32 ms per token,    88.30 tokens per second)
       eval time =    4239.03 ms /    11 tokens (  385.37 ms per token,     2.59 tokens per second)
      total time =    5699.92 ms /   140 tokens
slot      release: id  3 | task 281 | stop processing: n_tokens = 216, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.352 (> 0.100 thold), f_keep = 0.356
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 216, total state size = 33.753 MiB
srv          load:  - looking for better prompt, base f_keep = 0.356, sim = 0.352
srv        update:  - cache state: 14 prompts, 622.402 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv  get_availabl: prompt cache update took 4.25 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 298 | processing task, is_child = 0
slot update_slots: id  3 | task 298 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 219
slot update_slots: id  3 | task 298 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 298 | prompt processing progress, n_tokens = 219, batch.n_tokens = 145, progress = 1.000000
slot update_slots: id  3 | task 298 | prompt done, n_tokens = 219, batch.n_tokens = 145
slot init_sampler: id  3 | task 298 | init sampler, took 0.02 ms, tokens: text = 219, total = 219
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 293 | 
prompt eval time =     890.15 ms /    64 tokens (   13.91 ms per token,    71.90 tokens per second)
       eval time =    3893.01 ms /    10 tokens (  389.30 ms per token,     2.57 tokens per second)
      total time =    4783.16 ms /    74 tokens
slot      release: id  0 | task 293 | stop processing: n_tokens = 150, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.770 (> 0.100 thold), f_keep = 0.513
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 302 | processing task, is_child = 0
slot update_slots: id  0 | task 302 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 100
slot update_slots: id  0 | task 302 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 302 | prompt processing progress, n_tokens = 100, batch.n_tokens = 26, progress = 1.000000
slot update_slots: id  0 | task 302 | prompt done, n_tokens = 100, batch.n_tokens = 26
slot init_sampler: id  0 | task 302 | init sampler, took 0.01 ms, tokens: text = 100, total = 100
slot print_timing: id  2 | task 287 | 
prompt eval time =     901.63 ms /    85 tokens (   10.61 ms per token,    94.27 tokens per second)
       eval time =    5720.14 ms /    14 tokens (  408.58 ms per token,     2.45 tokens per second)
      total time =    6621.77 ms /    99 tokens
slot      release: id  2 | task 287 | stop processing: n_tokens = 175, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.108 (> 0.100 thold), f_keep = 0.440
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 175, total state size = 27.347 MiB
srv          load:  - looking for better prompt, base f_keep = 0.440, sim = 0.108
srv        update:  - cache state: 15 prompts, 649.749 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv  get_availabl: prompt cache update took 5.02 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 308 | processing task, is_child = 0
slot update_slots: id  2 | task 308 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 715
slot update_slots: id  2 | task 308 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 308 | prompt processing progress, n_tokens = 715, batch.n_tokens = 641, progress = 1.000000
slot update_slots: id  2 | task 308 | prompt done, n_tokens = 715, batch.n_tokens = 641
slot init_sampler: id  2 | task 308 | init sampler, took 0.07 ms, tokens: text = 715, total = 715
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 296 | 
prompt eval time =     406.03 ms /     3 tokens (  135.34 ms per token,     7.39 tokens per second)
       eval time =   10787.77 ms /    14 tokens (  770.55 ms per token,     1.30 tokens per second)
      total time =   11193.79 ms /    17 tokens
slot      release: id  1 | task 296 | stop processing: n_tokens = 93, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.828
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 309 | processing task, is_child = 0
slot update_slots: id  1 | task 309 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  1 | task 309 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 309 | prompt processing progress, n_tokens = 84, batch.n_tokens = 10, progress = 1.000000
slot update_slots: id  1 | task 309 | prompt done, n_tokens = 84, batch.n_tokens = 10
slot init_sampler: id  1 | task 309 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 298 | 
prompt eval time =    1452.61 ms /   142 tokens (   10.23 ms per token,    97.76 tokens per second)
       eval time =    9385.61 ms /    13 tokens (  721.97 ms per token,     1.39 tokens per second)
      total time =   10838.22 ms /   155 tokens
slot      release: id  3 | task 298 | stop processing: n_tokens = 231, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.940 (> 0.100 thold), f_keep = 0.342
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 231, total state size = 36.097 MiB
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv          load:  - looking for better prompt, base f_keep = 0.342, sim = 0.940
srv        update:  - cache state: 16 prompts, 685.846 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv  get_availabl: prompt cache update took 6.81 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 313 | processing task, is_child = 0
slot update_slots: id  3 | task 313 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  3 | task 313 | n_tokens = 79, memory_seq_rm [79, end)
slot update_slots: id  3 | task 313 | prompt processing progress, n_tokens = 84, batch.n_tokens = 8, progress = 1.000000
slot update_slots: id  3 | task 313 | prompt done, n_tokens = 84, batch.n_tokens = 8
slot init_sampler: id  3 | task 313 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 308 | 
prompt eval time =    6081.31 ms /   638 tokens (    9.53 ms per token,   104.91 tokens per second)
       eval time =    2934.48 ms /    10 tokens (  293.45 ms per token,     3.41 tokens per second)
      total time =    9015.78 ms /   648 tokens
slot      release: id  2 | task 308 | stop processing: n_tokens = 724, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.865 (> 0.100 thold), f_keep = 0.106
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 724, total state size = 113.134 MiB
srv          load:  - looking for better prompt, base f_keep = 0.106, sim = 0.865
srv        update:  - cache state: 17 prompts, 798.981 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv  get_availabl: prompt cache update took 42.50 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 320 | processing task, is_child = 0
slot update_slots: id  2 | task 320 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 89
slot update_slots: id  2 | task 320 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 320 | prompt processing progress, n_tokens = 89, batch.n_tokens = 15, progress = 1.000000
slot update_slots: id  2 | task 320 | prompt done, n_tokens = 89, batch.n_tokens = 15
slot init_sampler: id  2 | task 320 | init sampler, took 0.01 ms, tokens: text = 89, total = 89
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 302 | 
prompt eval time =     344.03 ms /    23 tokens (   14.96 ms per token,    66.86 tokens per second)
       eval time =   10002.52 ms /    14 tokens (  714.47 ms per token,     1.40 tokens per second)
      total time =   10346.54 ms /    37 tokens
slot      release: id  0 | task 302 | stop processing: n_tokens = 113, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.740 (> 0.100 thold), f_keep = 0.681
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 323 | processing task, is_child = 0
slot update_slots: id  0 | task 323 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 104
slot update_slots: id  0 | task 323 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 323 | prompt processing progress, n_tokens = 104, batch.n_tokens = 30, progress = 1.000000
slot update_slots: id  0 | task 323 | prompt done, n_tokens = 104, batch.n_tokens = 30
slot init_sampler: id  0 | task 323 | init sampler, took 0.01 ms, tokens: text = 104, total = 104
slot print_timing: id  2 | task 320 | 
prompt eval time =     350.24 ms /    12 tokens (   29.19 ms per token,    34.26 tokens per second)
       eval time =    2673.46 ms /    10 tokens (  267.35 ms per token,     3.74 tokens per second)
      total time =    3023.70 ms /    22 tokens
slot      release: id  2 | task 320 | stop processing: n_tokens = 98, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 313 | 
prompt eval time =     562.70 ms /     5 tokens (  112.54 ms per token,     8.89 tokens per second)
       eval time =    3066.52 ms /    11 tokens (  278.77 ms per token,     3.59 tokens per second)
      total time =    3629.21 ms /    16 tokens
slot      release: id  3 | task 313 | stop processing: n_tokens = 94, truncated = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.865 (> 0.100 thold), f_keep = 0.786
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 329 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.895 (> 0.100 thold), f_keep = 0.819
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 325 | processing task, is_child = 0
slot update_slots: id  2 | task 329 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 89
slot update_slots: id  2 | task 329 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  2 | task 329 | prompt processing progress, n_tokens = 89, batch.n_tokens = 14, progress = 1.000000
slot update_slots: id  2 | task 329 | prompt done, n_tokens = 89, batch.n_tokens = 14
slot init_sampler: id  2 | task 329 | init sampler, took 0.01 ms, tokens: text = 89, total = 89
slot update_slots: id  3 | task 325 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 86
slot update_slots: id  3 | task 325 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 325 | prompt processing progress, n_tokens = 86, batch.n_tokens = 23, progress = 1.000000
slot update_slots: id  3 | task 325 | prompt done, n_tokens = 86, batch.n_tokens = 23
slot init_sampler: id  3 | task 325 | init sampler, took 0.01 ms, tokens: text = 86, total = 86
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 309 | 
prompt eval time =     341.26 ms /     7 tokens (   48.75 ms per token,    20.51 tokens per second)
       eval time =    3973.72 ms /    13 tokens (  305.67 ms per token,     3.27 tokens per second)
      total time =    4314.98 ms /    20 tokens
slot      release: id  1 | task 309 | stop processing: n_tokens = 96, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.928 (> 0.100 thold), f_keep = 0.802
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 338 | processing task, is_child = 0
slot update_slots: id  1 | task 338 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 83
slot update_slots: id  1 | task 338 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 338 | prompt processing progress, n_tokens = 83, batch.n_tokens = 9, progress = 1.000000
slot update_slots: id  1 | task 338 | prompt done, n_tokens = 83, batch.n_tokens = 9
slot init_sampler: id  1 | task 338 | init sampler, took 0.01 ms, tokens: text = 83, total = 83
slot print_timing: id  0 | task 323 | 
prompt eval time =     346.87 ms /    27 tokens (   12.85 ms per token,    77.84 tokens per second)
       eval time =    4172.84 ms /    15 tokens (  278.19 ms per token,     3.59 tokens per second)
      total time =    4519.71 ms /    42 tokens
slot      release: id  0 | task 323 | stop processing: n_tokens = 118, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.239 (> 0.100 thold), f_keep = 0.653
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 340 | processing task, is_child = 0
slot update_slots: id  0 | task 340 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 322
slot update_slots: id  0 | task 340 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 340 | prompt processing progress, n_tokens = 322, batch.n_tokens = 248, progress = 1.000000
slot update_slots: id  0 | task 340 | prompt done, n_tokens = 322, batch.n_tokens = 248
slot init_sampler: id  0 | task 340 | init sampler, took 0.03 ms, tokens: text = 322, total = 322
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 338 | 
prompt eval time =     333.02 ms /     6 tokens (   55.50 ms per token,    18.02 tokens per second)
       eval time =    4633.49 ms /    10 tokens (  463.35 ms per token,     2.16 tokens per second)
      total time =    4966.51 ms /    16 tokens
slot      release: id  1 | task 338 | stop processing: n_tokens = 92, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 329 | 
prompt eval time =     344.39 ms /    12 tokens (   28.70 ms per token,    34.84 tokens per second)
       eval time =    4976.36 ms /    11 tokens (  452.40 ms per token,     2.21 tokens per second)
      total time =    5320.75 ms /    23 tokens
slot      release: id  2 | task 329 | stop processing: n_tokens = 99, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 325 | 
prompt eval time =     353.89 ms /     9 tokens (   39.32 ms per token,    25.43 tokens per second)
       eval time =    4966.96 ms /    11 tokens (  451.54 ms per token,     2.21 tokens per second)
      total time =    5320.85 ms /    20 tokens
slot      release: id  3 | task 325 | stop processing: n_tokens = 96, truncated = 0
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.786 (> 0.100 thold), f_keep = 0.837
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 354 | processing task, is_child = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.846 (> 0.100 thold), f_keep = 0.778
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 344 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.875 (> 0.100 thold), f_keep = 0.802
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 342 | processing task, is_child = 0
slot update_slots: id  1 | task 354 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 98
slot update_slots: id  1 | task 354 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 354 | prompt processing progress, n_tokens = 98, batch.n_tokens = 22, progress = 1.000000
slot update_slots: id  1 | task 354 | prompt done, n_tokens = 98, batch.n_tokens = 22
slot init_sampler: id  1 | task 354 | init sampler, took 0.01 ms, tokens: text = 98, total = 98
slot update_slots: id  2 | task 344 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 91
slot update_slots: id  2 | task 344 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 344 | prompt processing progress, n_tokens = 91, batch.n_tokens = 36, progress = 1.000000
slot update_slots: id  2 | task 344 | prompt done, n_tokens = 91, batch.n_tokens = 36
slot init_sampler: id  2 | task 344 | init sampler, took 0.01 ms, tokens: text = 91, total = 91
slot update_slots: id  3 | task 342 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 88
slot update_slots: id  3 | task 342 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 342 | prompt processing progress, n_tokens = 88, batch.n_tokens = 47, progress = 1.000000
slot update_slots: id  3 | task 342 | prompt done, n_tokens = 88, batch.n_tokens = 47
slot init_sampler: id  3 | task 342 | init sampler, took 0.01 ms, tokens: text = 88, total = 88
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 340 | 
prompt eval time =    2300.03 ms /   245 tokens (    9.39 ms per token,   106.52 tokens per second)
       eval time =    3521.96 ms /    12 tokens (  293.50 ms per token,     3.41 tokens per second)
      total time =    5821.99 ms /   257 tokens
slot      release: id  0 | task 340 | stop processing: n_tokens = 333, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.546 (> 0.100 thold), f_keep = 0.231
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 333, total state size = 52.036 MiB
srv          load:  - looking for better prompt, base f_keep = 0.231, sim = 0.546
srv        update:  - cache state: 18 prompts, 851.017 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv  get_availabl: prompt cache update took 9.22 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 355 | processing task, is_child = 0
slot update_slots: id  0 | task 355 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 141
slot update_slots: id  0 | task 355 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 355 | prompt processing progress, n_tokens = 141, batch.n_tokens = 67, progress = 1.000000
slot update_slots: id  0 | task 355 | prompt done, n_tokens = 141, batch.n_tokens = 67
slot init_sampler: id  0 | task 355 | init sampler, took 0.01 ms, tokens: text = 141, total = 141
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 344 | 
prompt eval time =     617.90 ms /    14 tokens (   44.14 ms per token,    22.66 tokens per second)
       eval time =    3217.53 ms /    10 tokens (  321.75 ms per token,     3.11 tokens per second)
      total time =    3835.43 ms /    24 tokens
slot      release: id  2 | task 344 | stop processing: n_tokens = 100, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.846 (> 0.100 thold), f_keep = 0.770
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 356 | processing task, is_child = 0
slot update_slots: id  2 | task 356 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 91
slot update_slots: id  2 | task 356 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 356 | prompt processing progress, n_tokens = 91, batch.n_tokens = 17, progress = 1.000000
slot update_slots: id  2 | task 356 | prompt done, n_tokens = 91, batch.n_tokens = 17
slot init_sampler: id  2 | task 356 | init sampler, took 0.01 ms, tokens: text = 91, total = 91
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 354 | 
prompt eval time =     611.22 ms /    21 tokens (   29.11 ms per token,    34.36 tokens per second)
       eval time =    4159.48 ms /    13 tokens (  319.96 ms per token,     3.13 tokens per second)
      total time =    4770.71 ms /    34 tokens
slot      release: id  1 | task 354 | stop processing: n_tokens = 110, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.811 (> 0.100 thold), f_keep = 0.700
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 364 | processing task, is_child = 0
slot update_slots: id  1 | task 364 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 95
slot update_slots: id  1 | task 364 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 364 | prompt processing progress, n_tokens = 95, batch.n_tokens = 21, progress = 1.000000
slot update_slots: id  1 | task 364 | prompt done, n_tokens = 95, batch.n_tokens = 21
slot init_sampler: id  1 | task 364 | init sampler, took 0.01 ms, tokens: text = 95, total = 95
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 342 | 
prompt eval time =     624.61 ms /    11 tokens (   56.78 ms per token,    17.61 tokens per second)
       eval time =    4495.35 ms /    14 tokens (  321.10 ms per token,     3.11 tokens per second)
      total time =    5119.96 ms /    25 tokens
slot      release: id  3 | task 342 | stop processing: n_tokens = 101, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.885 (> 0.100 thold), f_keep = 0.762
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 369 | processing task, is_child = 0
slot update_slots: id  3 | task 369 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 87
slot update_slots: id  3 | task 369 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 369 | prompt processing progress, n_tokens = 87, batch.n_tokens = 13, progress = 1.000000
slot update_slots: id  3 | task 369 | prompt done, n_tokens = 87, batch.n_tokens = 13
slot init_sampler: id  3 | task 369 | init sampler, took 0.01 ms, tokens: text = 87, total = 87
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 355 | 
prompt eval time =     890.75 ms /    64 tokens (   13.92 ms per token,    71.85 tokens per second)
       eval time =    3652.65 ms /    13 tokens (  280.97 ms per token,     3.56 tokens per second)
      total time =    4543.40 ms /    77 tokens
slot      release: id  0 | task 355 | stop processing: n_tokens = 153, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 356 | 
prompt eval time =     354.72 ms /    14 tokens (   25.34 ms per token,    39.47 tokens per second)
       eval time =    3011.14 ms /    11 tokens (  273.74 ms per token,     3.65 tokens per second)
      total time =    3365.86 ms /    25 tokens
slot      release: id  2 | task 356 | stop processing: n_tokens = 101, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.104 (> 0.100 thold), f_keep = 0.503
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 371 | processing task, is_child = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.554 (> 0.100 thold), f_keep = 0.762
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 370 | processing task, is_child = 0
slot update_slots: id  0 | task 371 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 739
slot update_slots: id  0 | task 371 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 371 | prompt processing progress, n_tokens = 739, batch.n_tokens = 664, progress = 1.000000
slot update_slots: id  0 | task 371 | prompt done, n_tokens = 739, batch.n_tokens = 664
slot init_sampler: id  0 | task 371 | init sampler, took 0.06 ms, tokens: text = 739, total = 739
slot update_slots: id  2 | task 370 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 139
slot update_slots: id  2 | task 370 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 370 | prompt processing progress, n_tokens = 139, batch.n_tokens = 726, progress = 1.000000
slot update_slots: id  2 | task 370 | prompt done, n_tokens = 139, batch.n_tokens = 726
slot init_sampler: id  2 | task 370 | init sampler, took 0.01 ms, tokens: text = 139, total = 139
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 369 | 
prompt eval time =     345.01 ms /    10 tokens (   34.50 ms per token,    28.98 tokens per second)
       eval time =    9230.17 ms /    10 tokens (  923.02 ms per token,     1.08 tokens per second)
      total time =    9575.18 ms /    20 tokens
slot      release: id  3 | task 369 | stop processing: n_tokens = 96, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.802
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 380 | processing task, is_child = 0
slot update_slots: id  3 | task 380 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  3 | task 380 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 380 | prompt processing progress, n_tokens = 84, batch.n_tokens = 10, progress = 1.000000
slot update_slots: id  3 | task 380 | prompt done, n_tokens = 84, batch.n_tokens = 10
slot init_sampler: id  3 | task 380 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 364 | 
prompt eval time =     341.99 ms /    18 tokens (   19.00 ms per token,    52.63 tokens per second)
       eval time =    9923.31 ms /    12 tokens (  826.94 ms per token,     1.21 tokens per second)
      total time =   10265.30 ms /    30 tokens
slot      release: id  1 | task 364 | stop processing: n_tokens = 106, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.726
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 383 | processing task, is_child = 0
slot update_slots: id  1 | task 383 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  1 | task 383 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 383 | prompt processing progress, n_tokens = 84, batch.n_tokens = 10, progress = 1.000000
slot update_slots: id  1 | task 383 | prompt done, n_tokens = 84, batch.n_tokens = 10
slot init_sampler: id  1 | task 383 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
slot print_timing: id  2 | task 370 | 
prompt eval time =    6910.06 ms /    62 tokens (  111.45 ms per token,     8.97 tokens per second)
       eval time =    3027.17 ms /    11 tokens (  275.20 ms per token,     3.63 tokens per second)
      total time =    9937.23 ms /    73 tokens
slot      release: id  2 | task 370 | stop processing: n_tokens = 149, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.726 (> 0.100 thold), f_keep = 0.517
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 387 | processing task, is_child = 0
slot update_slots: id  2 | task 387 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 106
slot update_slots: id  2 | task 387 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 387 | prompt processing progress, n_tokens = 106, batch.n_tokens = 32, progress = 1.000000
slot update_slots: id  2 | task 387 | prompt done, n_tokens = 106, batch.n_tokens = 32
slot init_sampler: id  2 | task 387 | init sampler, took 0.01 ms, tokens: text = 106, total = 106
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 380 | 
prompt eval time =     362.41 ms /     7 tokens (   51.77 ms per token,    19.32 tokens per second)
       eval time =    2721.85 ms /    10 tokens (  272.18 ms per token,     3.67 tokens per second)
      total time =    3084.26 ms /    17 tokens
slot      release: id  3 | task 380 | stop processing: n_tokens = 93, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.928 (> 0.100 thold), f_keep = 0.828
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 389 | processing task, is_child = 0
slot update_slots: id  3 | task 389 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 83
slot update_slots: id  3 | task 389 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 389 | prompt processing progress, n_tokens = 83, batch.n_tokens = 9, progress = 1.000000
slot update_slots: id  3 | task 389 | prompt done, n_tokens = 83, batch.n_tokens = 9
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot init_sampler: id  3 | task 389 | init sampler, took 0.01 ms, tokens: text = 83, total = 83
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 371 | 
prompt eval time =    6902.38 ms /   662 tokens (   10.43 ms per token,    95.91 tokens per second)
       eval time =    4009.20 ms /    14 tokens (  286.37 ms per token,     3.49 tokens per second)
      total time =   10911.58 ms /   676 tokens
slot      release: id  0 | task 371 | stop processing: n_tokens = 752, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.837 (> 0.100 thold), f_keep = 0.102
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 752, total state size = 117.510 MiB
srv  params_from_: Chat format: Content-only
srv          load:  - looking for better prompt, base f_keep = 0.102, sim = 0.837
srv        update:  - cache state: 19 prompts, 968.526 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv  get_availabl: prompt cache update took 37.52 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 397 | processing task, is_child = 0
slot update_slots: id  0 | task 397 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 92
slot update_slots: id  0 | task 397 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 397 | prompt processing progress, n_tokens = 92, batch.n_tokens = 18, progress = 1.000000
slot update_slots: id  0 | task 397 | prompt done, n_tokens = 92, batch.n_tokens = 18
slot init_sampler: id  0 | task 397 | init sampler, took 0.01 ms, tokens: text = 92, total = 92
slot print_timing: id  1 | task 383 | 
prompt eval time =     341.23 ms /     7 tokens (   48.75 ms per token,    20.51 tokens per second)
       eval time =    3107.64 ms /    11 tokens (  282.51 ms per token,     3.54 tokens per second)
      total time =    3448.87 ms /    18 tokens
slot      release: id  1 | task 383 | stop processing: n_tokens = 94, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.886 (> 0.100 thold), f_keep = 0.830
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 398 | processing task, is_child = 0
slot update_slots: id  1 | task 398 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 88
slot update_slots: id  1 | task 398 | n_tokens = 78, memory_seq_rm [78, end)
slot update_slots: id  1 | task 398 | prompt processing progress, n_tokens = 88, batch.n_tokens = 13, progress = 1.000000
slot update_slots: id  1 | task 398 | prompt done, n_tokens = 88, batch.n_tokens = 13
slot init_sampler: id  1 | task 398 | init sampler, took 0.01 ms, tokens: text = 88, total = 88
slot print_timing: id  2 | task 387 | 
prompt eval time =     346.28 ms /    29 tokens (   11.94 ms per token,    83.75 tokens per second)
       eval time =    3124.41 ms /    11 tokens (  284.04 ms per token,     3.52 tokens per second)
      total time =    3470.68 ms /    40 tokens
slot      release: id  2 | task 387 | stop processing: n_tokens = 116, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.675 (> 0.100 thold), f_keep = 0.664
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 402 | processing task, is_child = 0
slot update_slots: id  2 | task 402 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 114
slot update_slots: id  2 | task 402 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 402 | prompt processing progress, n_tokens = 114, batch.n_tokens = 40, progress = 1.000000
slot update_slots: id  2 | task 402 | prompt done, n_tokens = 114, batch.n_tokens = 40
slot init_sampler: id  2 | task 402 | init sampler, took 0.01 ms, tokens: text = 114, total = 114
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 389 | 
prompt eval time =     341.64 ms /     6 tokens (   56.94 ms per token,    17.56 tokens per second)
       eval time =    3090.84 ms /    10 tokens (  309.08 ms per token,     3.24 tokens per second)
      total time =    3432.48 ms /    16 tokens
slot      release: id  3 | task 389 | stop processing: n_tokens = 92, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.811 (> 0.100 thold), f_keep = 0.837
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 403 | processing task, is_child = 0
slot update_slots: id  3 | task 403 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 95
slot update_slots: id  3 | task 403 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 403 | prompt processing progress, n_tokens = 95, batch.n_tokens = 21, progress = 1.000000
slot update_slots: id  3 | task 403 | prompt done, n_tokens = 95, batch.n_tokens = 21
slot init_sampler: id  3 | task 403 | init sampler, took 0.01 ms, tokens: text = 95, total = 95
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 398 | 
prompt eval time =     337.18 ms /    10 tokens (   33.72 ms per token,    29.66 tokens per second)
       eval time =    3282.92 ms /    11 tokens (  298.45 ms per token,     3.35 tokens per second)
      total time =    3620.11 ms /    21 tokens
slot      release: id  1 | task 398 | stop processing: n_tokens = 98, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.150 (> 0.100 thold), f_keep = 0.786
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 412 | processing task, is_child = 0
slot update_slots: id  1 | task 412 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 512
slot update_slots: id  1 | task 412 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 412 | prompt processing progress, n_tokens = 512, batch.n_tokens = 438, progress = 1.000000
slot update_slots: id  1 | task 412 | prompt done, n_tokens = 512, batch.n_tokens = 438
slot init_sampler: id  1 | task 412 | init sampler, took 0.06 ms, tokens: text = 512, total = 512
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 397 | 
prompt eval time =     347.58 ms /    15 tokens (   23.17 ms per token,    43.16 tokens per second)
       eval time =    8009.00 ms /    14 tokens (  572.07 ms per token,     1.75 tokens per second)
      total time =    8356.58 ms /    29 tokens
slot      release: id  0 | task 397 | stop processing: n_tokens = 105, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.733
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 415 | processing task, is_child = 0
slot update_slots: id  0 | task 415 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 84
slot update_slots: id  0 | task 415 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 415 | prompt processing progress, n_tokens = 84, batch.n_tokens = 10, progress = 1.000000
slot update_slots: id  0 | task 415 | prompt done, n_tokens = 84, batch.n_tokens = 10
slot init_sampler: id  0 | task 415 | init sampler, took 0.01 ms, tokens: text = 84, total = 84
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 402 | 
prompt eval time =     601.83 ms /    37 tokens (   16.27 ms per token,    61.48 tokens per second)
       eval time =    6803.13 ms /    11 tokens (  618.47 ms per token,     1.62 tokens per second)
      total time =    7404.95 ms /    48 tokens
slot      release: id  2 | task 402 | stop processing: n_tokens = 124, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.740 (> 0.100 thold), f_keep = 0.621
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 416 | processing task, is_child = 0
slot update_slots: id  2 | task 416 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 104
slot update_slots: id  2 | task 416 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 416 | prompt processing progress, n_tokens = 104, batch.n_tokens = 30, progress = 1.000000
slot update_slots: id  2 | task 416 | prompt done, n_tokens = 104, batch.n_tokens = 30
slot init_sampler: id  2 | task 416 | init sampler, took 0.01 ms, tokens: text = 104, total = 104
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 403 | 
prompt eval time =     351.56 ms /    18 tokens (   19.53 ms per token,    51.20 tokens per second)
       eval time =    6799.02 ms /    11 tokens (  618.09 ms per token,     1.62 tokens per second)
      total time =    7150.58 ms /    29 tokens
slot      release: id  3 | task 403 | stop processing: n_tokens = 105, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.720 (> 0.100 thold), f_keep = 0.733
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 418 | processing task, is_child = 0
slot update_slots: id  3 | task 418 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 107
slot update_slots: id  3 | task 418 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 418 | prompt processing progress, n_tokens = 107, batch.n_tokens = 33, progress = 1.000000
slot update_slots: id  3 | task 418 | prompt done, n_tokens = 107, batch.n_tokens = 33
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot init_sampler: id  3 | task 418 | init sampler, took 0.01 ms, tokens: text = 107, total = 107
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 415 | 
prompt eval time =     339.92 ms /     7 tokens (   48.56 ms per token,    20.59 tokens per second)
       eval time =    3267.39 ms /    11 tokens (  297.04 ms per token,     3.37 tokens per second)
      total time =    3607.31 ms /    18 tokens
slot      release: id  0 | task 415 | stop processing: n_tokens = 94, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  1 | task 412 | 
prompt eval time =    4078.10 ms /   435 tokens (    9.37 ms per token,   106.67 tokens per second)
       eval time =    3897.56 ms /    13 tokens (  299.81 ms per token,     3.34 tokens per second)
      total time =    7975.65 ms /   448 tokens
slot      release: id  1 | task 412 | stop processing: n_tokens = 524, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.554 (> 0.100 thold), f_keep = 0.819
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 429 | processing task, is_child = 0
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.856 (> 0.100 thold), f_keep = 0.147
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 524, total state size = 81.882 MiB
srv  params_from_: Chat format: Content-only
srv          load:  - looking for better prompt, base f_keep = 0.147, sim = 0.856
srv        update:  - cache state: 20 prompts, 1050.408 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv  get_availabl: prompt cache update took 8.56 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 427 | processing task, is_child = 0
slot update_slots: id  0 | task 429 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 139
slot update_slots: id  0 | task 429 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 429 | prompt processing progress, n_tokens = 139, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  0 | task 429 | prompt done, n_tokens = 139, batch.n_tokens = 64
slot init_sampler: id  0 | task 429 | init sampler, took 0.01 ms, tokens: text = 139, total = 139
slot update_slots: id  1 | task 427 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 90
slot update_slots: id  1 | task 427 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 427 | prompt processing progress, n_tokens = 90, batch.n_tokens = 77, progress = 1.000000
slot update_slots: id  1 | task 427 | prompt done, n_tokens = 90, batch.n_tokens = 77
slot init_sampler: id  1 | task 427 | init sampler, took 0.01 ms, tokens: text = 90, total = 90
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 416 | 
prompt eval time =     347.20 ms /    27 tokens (   12.86 ms per token,    77.76 tokens per second)
       eval time =    4729.01 ms /    14 tokens (  337.79 ms per token,     2.96 tokens per second)
      total time =    5076.21 ms /    41 tokens
slot      release: id  2 | task 416 | stop processing: n_tokens = 117, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.658
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 433 | processing task, is_child = 0
slot update_slots: id  2 | task 433 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 85
slot update_slots: id  2 | task 433 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 433 | prompt processing progress, n_tokens = 85, batch.n_tokens = 11, progress = 1.000000
slot update_slots: id  2 | task 433 | prompt done, n_tokens = 85, batch.n_tokens = 11
slot init_sampler: id  2 | task 433 | init sampler, took 0.01 ms, tokens: text = 85, total = 85
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 418 | 
prompt eval time =     601.38 ms /    30 tokens (   20.05 ms per token,    49.88 tokens per second)
       eval time =    4755.88 ms /    15 tokens (  317.06 ms per token,     3.15 tokens per second)
      total time =    5357.27 ms /    45 tokens
slot      release: id  3 | task 418 | stop processing: n_tokens = 121, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.875 (> 0.100 thold), f_keep = 0.636
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 436 | processing task, is_child = 0
slot update_slots: id  3 | task 436 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 88
slot update_slots: id  3 | task 436 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 436 | prompt processing progress, n_tokens = 88, batch.n_tokens = 14, progress = 1.000000
slot update_slots: id  3 | task 436 | prompt done, n_tokens = 88, batch.n_tokens = 14
slot init_sampler: id  3 | task 436 | init sampler, took 0.01 ms, tokens: text = 88, total = 88
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 427 | 
prompt eval time =     905.83 ms /    13 tokens (   69.68 ms per token,    14.35 tokens per second)
       eval time =    3011.52 ms /    11 tokens (  273.77 ms per token,     3.65 tokens per second)
      total time =    3917.35 ms /    24 tokens
slot      release: id  1 | task 427 | stop processing: n_tokens = 100, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.438 (> 0.100 thold), f_keep = 0.770
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 442 | processing task, is_child = 0
slot update_slots: id  1 | task 442 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 176
slot update_slots: id  1 | task 442 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 442 | prompt processing progress, n_tokens = 176, batch.n_tokens = 102, progress = 1.000000
slot update_slots: id  1 | task 442 | prompt done, n_tokens = 176, batch.n_tokens = 102
slot init_sampler: id  1 | task 442 | init sampler, took 0.02 ms, tokens: text = 176, total = 176
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 429 | 
prompt eval time =     895.04 ms /    62 tokens (   14.44 ms per token,    69.27 tokens per second)
       eval time =    4180.71 ms /    12 tokens (  348.39 ms per token,     2.87 tokens per second)
      total time =    5075.75 ms /    74 tokens
slot      release: id  0 | task 429 | stop processing: n_tokens = 150, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.144 (> 0.100 thold), f_keep = 0.513
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 444 | processing task, is_child = 0
slot update_slots: id  0 | task 444 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 535
slot update_slots: id  0 | task 444 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 444 | prompt processing progress, n_tokens = 535, batch.n_tokens = 461, progress = 1.000000
slot update_slots: id  0 | task 444 | prompt done, n_tokens = 535, batch.n_tokens = 461
slot init_sampler: id  0 | task 444 | init sampler, took 0.08 ms, tokens: text = 535, total = 535
slot print_timing: id  3 | task 436 | 
prompt eval time =     344.48 ms /    11 tokens (   31.32 ms per token,    31.93 tokens per second)
       eval time =    7520.13 ms /    10 tokens (  752.01 ms per token,     1.33 tokens per second)
      total time =    7864.60 ms /    21 tokens
slot      release: id  3 | task 436 | stop processing: n_tokens = 97, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.464 (> 0.100 thold), f_keep = 0.794
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 449 | processing task, is_child = 0
slot update_slots: id  3 | task 449 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 166
slot update_slots: id  3 | task 449 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 449 | prompt processing progress, n_tokens = 166, batch.n_tokens = 92, progress = 1.000000
slot update_slots: id  3 | task 449 | prompt done, n_tokens = 166, batch.n_tokens = 92
slot init_sampler: id  3 | task 449 | init sampler, took 0.01 ms, tokens: text = 166, total = 166
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 444 | 
prompt eval time =    4311.64 ms /   458 tokens (    9.41 ms per token,   106.22 tokens per second)
       eval time =    2935.58 ms /     9 tokens (  326.18 ms per token,     3.07 tokens per second)
      total time =    7247.22 ms /   467 tokens
slot      release: id  0 | task 444 | stop processing: n_tokens = 543, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  1 | task 442 | 
prompt eval time =    1157.93 ms /    99 tokens (   11.70 ms per token,    85.50 tokens per second)
       eval time =    7258.41 ms /    10 tokens (  725.84 ms per token,     1.38 tokens per second)
      total time =    8416.34 ms /   109 tokens
slot      release: id  1 | task 442 | stop processing: n_tokens = 185, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.865 (> 0.100 thold), f_keep = 0.142
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 543, total state size = 84.851 MiB
srv          load:  - looking for better prompt, base f_keep = 0.142, sim = 0.865
srv        update:  - cache state: 21 prompts, 1135.259 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv  get_availabl: prompt cache update took 26.32 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 460 | processing task, is_child = 0
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.688 (> 0.100 thold), f_keep = 0.416
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 185, total state size = 28.909 MiB
srv          load:  - looking for better prompt, base f_keep = 0.416, sim = 0.688
srv        update:  - cache state: 22 prompts, 1164.168 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv  get_availabl: prompt cache update took 5.03 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 451 | processing task, is_child = 0
slot update_slots: id  0 | task 460 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 89
slot update_slots: id  0 | task 460 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 460 | prompt processing progress, n_tokens = 89, batch.n_tokens = 14, progress = 1.000000
slot update_slots: id  0 | task 460 | prompt done, n_tokens = 89, batch.n_tokens = 14
slot init_sampler: id  0 | task 460 | init sampler, took 0.01 ms, tokens: text = 89, total = 89
slot update_slots: id  1 | task 451 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 112
slot update_slots: id  1 | task 451 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 451 | prompt processing progress, n_tokens = 112, batch.n_tokens = 49, progress = 1.000000
slot update_slots: id  1 | task 451 | prompt done, n_tokens = 112, batch.n_tokens = 49
slot init_sampler: id  1 | task 451 | init sampler, took 0.01 ms, tokens: text = 112, total = 112
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 433 | 
prompt eval time =     341.24 ms /     8 tokens (   42.65 ms per token,    23.44 tokens per second)
       eval time =    9699.17 ms /    14 tokens (  692.80 ms per token,     1.44 tokens per second)
      total time =   10040.41 ms /    22 tokens
slot      release: id  2 | task 433 | stop processing: n_tokens = 98, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.895 (> 0.100 thold), f_keep = 0.786
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 463 | processing task, is_child = 0
slot update_slots: id  2 | task 463 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 86
slot update_slots: id  2 | task 463 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 463 | prompt processing progress, n_tokens = 86, batch.n_tokens = 12, progress = 1.000000
slot update_slots: id  2 | task 463 | prompt done, n_tokens = 86, batch.n_tokens = 12
slot init_sampler: id  2 | task 463 | init sampler, took 0.01 ms, tokens: text = 86, total = 86
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 451 | 
prompt eval time =     611.98 ms /    35 tokens (   17.49 ms per token,    57.19 tokens per second)
       eval time =    2652.52 ms /    10 tokens (  265.25 ms per token,     3.77 tokens per second)
      total time =    3264.50 ms /    45 tokens
slot      release: id  1 | task 451 | stop processing: n_tokens = 121, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.636
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 465 | processing task, is_child = 0
slot update_slots: id  1 | task 465 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  1 | task 465 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 465 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  1 | task 465 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  1 | task 465 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 460 | 
prompt eval time =     605.33 ms /    12 tokens (   50.44 ms per token,    19.82 tokens per second)
       eval time =    3166.70 ms /    11 tokens (  287.88 ms per token,     3.47 tokens per second)
      total time =    3772.03 ms /    23 tokens
slot      release: id  0 | task 460 | stop processing: n_tokens = 99, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.778 (> 0.100 thold), f_keep = 0.778
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 466 | processing task, is_child = 0
slot update_slots: id  0 | task 466 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 99
slot update_slots: id  0 | task 466 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 466 | prompt processing progress, n_tokens = 99, batch.n_tokens = 25, progress = 1.000000
slot update_slots: id  0 | task 466 | prompt done, n_tokens = 99, batch.n_tokens = 25
slot init_sampler: id  0 | task 466 | init sampler, took 0.01 ms, tokens: text = 99, total = 99
slot print_timing: id  3 | task 449 | 
prompt eval time =     903.61 ms /    89 tokens (   10.15 ms per token,    98.49 tokens per second)
       eval time =    4449.81 ms /    14 tokens (  317.84 ms per token,     3.15 tokens per second)
      total time =    5353.43 ms /   103 tokens
slot      release: id  3 | task 449 | stop processing: n_tokens = 179, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.762 (> 0.100 thold), f_keep = 0.430
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 179, total state size = 27.972 MiB
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv          load:  - looking for better prompt, base f_keep = 0.430, sim = 0.762
srv        update:  - cache state: 23 prompts, 1192.140 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv  get_availabl: prompt cache update took 6.50 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 476 | processing task, is_child = 0
slot update_slots: id  3 | task 476 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 101
slot update_slots: id  3 | task 476 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 476 | prompt processing progress, n_tokens = 101, batch.n_tokens = 27, progress = 1.000000
slot update_slots: id  3 | task 476 | prompt done, n_tokens = 101, batch.n_tokens = 27
slot init_sampler: id  3 | task 476 | init sampler, took 0.01 ms, tokens: text = 101, total = 101
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 463 | 
prompt eval time =     348.05 ms /     9 tokens (   38.67 ms per token,    25.86 tokens per second)
       eval time =    4379.66 ms /    15 tokens (  291.98 ms per token,     3.42 tokens per second)
      total time =    4727.71 ms /    24 tokens
slot      release: id  2 | task 463 | stop processing: n_tokens = 100, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.856 (> 0.100 thold), f_keep = 0.770
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 477 | processing task, is_child = 0
slot update_slots: id  2 | task 477 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 90
slot update_slots: id  2 | task 477 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 477 | prompt processing progress, n_tokens = 90, batch.n_tokens = 16, progress = 1.000000
slot update_slots: id  2 | task 477 | prompt done, n_tokens = 90, batch.n_tokens = 16
slot init_sampler: id  2 | task 477 | init sampler, took 0.01 ms, tokens: text = 90, total = 90
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 465 | 
prompt eval time =     514.12 ms /     4 tokens (  128.53 ms per token,     7.78 tokens per second)
       eval time =    3067.74 ms /    11 tokens (  278.89 ms per token,     3.59 tokens per second)
      total time =    3581.86 ms /    15 tokens
slot      release: id  1 | task 465 | stop processing: n_tokens = 91, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.895 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 479 | processing task, is_child = 0
slot update_slots: id  1 | task 479 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 86
slot update_slots: id  1 | task 479 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 479 | prompt processing progress, n_tokens = 86, batch.n_tokens = 12, progress = 1.000000
slot update_slots: id  1 | task 479 | prompt done, n_tokens = 86, batch.n_tokens = 12
slot init_sampler: id  1 | task 479 | init sampler, took 0.01 ms, tokens: text = 86, total = 86
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 466 | 
prompt eval time =     344.36 ms /    22 tokens (   15.65 ms per token,    63.89 tokens per second)
       eval time =    3058.01 ms /    11 tokens (  278.00 ms per token,     3.60 tokens per second)
      total time =    3402.38 ms /    33 tokens
slot      release: id  0 | task 466 | stop processing: n_tokens = 109, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.658 (> 0.100 thold), f_keep = 0.706
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 481 | processing task, is_child = 0
slot update_slots: id  0 | task 481 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 117
slot update_slots: id  0 | task 481 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 481 | prompt processing progress, n_tokens = 117, batch.n_tokens = 43, progress = 1.000000
slot update_slots: id  0 | task 481 | prompt done, n_tokens = 117, batch.n_tokens = 43
slot init_sampler: id  0 | task 481 | init sampler, took 0.01 ms, tokens: text = 117, total = 117
slot print_timing: id  3 | task 476 | 
prompt eval time =     344.10 ms /    24 tokens (   14.34 ms per token,    69.75 tokens per second)
       eval time =    4450.32 ms /    15 tokens (  296.69 ms per token,     3.37 tokens per second)
      total time =    4794.42 ms /    39 tokens
slot      release: id  3 | task 476 | stop processing: n_tokens = 115, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.856 (> 0.100 thold), f_keep = 0.670
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 491 | processing task, is_child = 0
slot update_slots: id  3 | task 491 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 90
slot update_slots: id  3 | task 491 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 491 | prompt processing progress, n_tokens = 90, batch.n_tokens = 16, progress = 1.000000
slot update_slots: id  3 | task 491 | prompt done, n_tokens = 90, batch.n_tokens = 16
slot init_sampler: id  3 | task 491 | init sampler, took 0.01 ms, tokens: text = 90, total = 90
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 477 | 
prompt eval time =     344.60 ms /    13 tokens (   26.51 ms per token,    37.72 tokens per second)
       eval time =    4164.67 ms /    14 tokens (  297.48 ms per token,     3.36 tokens per second)
      total time =    4509.27 ms /    27 tokens
slot      release: id  2 | task 477 | stop processing: n_tokens = 103, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.748
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 492 | processing task, is_child = 0
slot update_slots: id  2 | task 492 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  2 | task 492 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 492 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  2 | task 492 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  2 | task 492 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
srv  params_from_: Chat format: Content-only
slot print_timing: id  1 | task 479 | 
prompt eval time =     341.91 ms /     9 tokens (   37.99 ms per token,    26.32 tokens per second)
       eval time =    4030.44 ms /    13 tokens (  310.03 ms per token,     3.23 tokens per second)
      total time =    4372.35 ms /    22 tokens
slot      release: id  1 | task 479 | stop processing: n_tokens = 98, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.928 (> 0.100 thold), f_keep = 0.786
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 496 | processing task, is_child = 0
slot update_slots: id  1 | task 496 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 83
slot update_slots: id  1 | task 496 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 496 | prompt processing progress, n_tokens = 83, batch.n_tokens = 9, progress = 1.000000
slot update_slots: id  1 | task 496 | prompt done, n_tokens = 83, batch.n_tokens = 9
slot init_sampler: id  1 | task 496 | init sampler, took 0.01 ms, tokens: text = 83, total = 83
slot print_timing: id  0 | task 481 | 
prompt eval time =     595.10 ms /    40 tokens (   14.88 ms per token,    67.22 tokens per second)
       eval time =    4067.43 ms /    14 tokens (  290.53 ms per token,     3.44 tokens per second)
      total time =    4662.54 ms /    54 tokens
slot      release: id  0 | task 481 | stop processing: n_tokens = 130, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.503 (> 0.100 thold), f_keep = 0.592
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 500 | processing task, is_child = 0
slot update_slots: id  0 | task 500 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 153
slot update_slots: id  0 | task 500 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 500 | prompt processing progress, n_tokens = 153, batch.n_tokens = 79, progress = 1.000000
slot update_slots: id  0 | task 500 | prompt done, n_tokens = 153, batch.n_tokens = 79
slot init_sampler: id  0 | task 500 | init sampler, took 0.02 ms, tokens: text = 153, total = 153
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 491 | 
prompt eval time =     344.80 ms /    13 tokens (   26.52 ms per token,    37.70 tokens per second)
       eval time =    4632.26 ms /    14 tokens (  330.88 ms per token,     3.02 tokens per second)
      total time =    4977.05 ms /    27 tokens
slot      release: id  3 | task 491 | stop processing: n_tokens = 103, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.291 (> 0.100 thold), f_keep = 0.748
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 506 | processing task, is_child = 0
slot update_slots: id  3 | task 506 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 265
slot update_slots: id  3 | task 506 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 506 | prompt processing progress, n_tokens = 265, batch.n_tokens = 191, progress = 1.000000
slot update_slots: id  3 | task 506 | prompt done, n_tokens = 265, batch.n_tokens = 191
slot init_sampler: id  3 | task 506 | init sampler, took 0.03 ms, tokens: text = 265, total = 265
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 492 | 
prompt eval time =     513.13 ms /     4 tokens (  128.28 ms per token,     7.80 tokens per second)
       eval time =    5842.57 ms /    14 tokens (  417.33 ms per token,     2.40 tokens per second)
      total time =    6355.70 ms /    18 tokens
slot      release: id  2 | task 492 | stop processing: n_tokens = 94, truncated = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.895 (> 0.100 thold), f_keep = 0.819
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 507 | processing task, is_child = 0
slot update_slots: id  2 | task 507 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 86
slot update_slots: id  2 | task 507 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 507 | prompt processing progress, n_tokens = 86, batch.n_tokens = 12, progress = 1.000000
slot update_slots: id  2 | task 507 | prompt done, n_tokens = 86, batch.n_tokens = 12
slot init_sampler: id  2 | task 507 | init sampler, took 0.01 ms, tokens: text = 86, total = 86
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 500 | 
prompt eval time =     894.23 ms /    76 tokens (   11.77 ms per token,    84.99 tokens per second)
       eval time =    4083.81 ms /    10 tokens (  408.38 ms per token,     2.45 tokens per second)
      total time =    4978.05 ms /    86 tokens
slot      release: id  0 | task 500 | stop processing: n_tokens = 162, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.846 (> 0.100 thold), f_keep = 0.475
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 162, total state size = 25.315 MiB
srv          load:  - looking for better prompt, base f_keep = 0.475, sim = 0.846
srv        update:  - cache state: 24 prompts, 1217.455 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv  get_availabl: prompt cache update took 7.26 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 515 | processing task, is_child = 0
slot update_slots: id  0 | task 515 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 91
slot update_slots: id  0 | task 515 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 515 | prompt processing progress, n_tokens = 91, batch.n_tokens = 17, progress = 1.000000
slot update_slots: id  0 | task 515 | prompt done, n_tokens = 91, batch.n_tokens = 17
slot init_sampler: id  0 | task 515 | init sampler, took 0.01 ms, tokens: text = 91, total = 91
slot print_timing: id  1 | task 496 | 
prompt eval time =     339.08 ms /     6 tokens (   56.51 ms per token,    17.70 tokens per second)
       eval time =    6212.39 ms /    15 tokens (  414.16 ms per token,     2.41 tokens per second)
      total time =    6551.47 ms /    21 tokens
slot      release: id  1 | task 496 | stop processing: n_tokens = 97, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.885 (> 0.100 thold), f_keep = 0.794
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 518 | processing task, is_child = 0
slot update_slots: id  1 | task 518 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 87
slot update_slots: id  1 | task 518 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 518 | prompt processing progress, n_tokens = 87, batch.n_tokens = 13, progress = 1.000000
slot update_slots: id  1 | task 518 | prompt done, n_tokens = 87, batch.n_tokens = 13
slot init_sampler: id  1 | task 518 | init sampler, took 0.01 ms, tokens: text = 87, total = 87
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 507 | 
prompt eval time =     345.08 ms /     9 tokens (   38.34 ms per token,    26.08 tokens per second)
       eval time =    3019.32 ms /    11 tokens (  274.48 ms per token,     3.64 tokens per second)
      total time =    3364.39 ms /    20 tokens
slot      release: id  2 | task 507 | stop processing: n_tokens = 96, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 506 | 
prompt eval time =    1720.65 ms /   188 tokens (    9.15 ms per token,   109.26 tokens per second)
       eval time =    3654.14 ms /    13 tokens (  281.09 ms per token,     3.56 tokens per second)
      total time =    5374.79 ms /   201 tokens
slot      release: id  3 | task 506 | stop processing: n_tokens = 277, truncated = 0
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.513 (> 0.100 thold), f_keep = 0.802
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 526 | processing task, is_child = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.352 (> 0.100 thold), f_keep = 0.278
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 277, total state size = 43.285 MiB
srv          load:  - looking for better prompt, base f_keep = 0.278, sim = 0.352
srv        update:  - cache state: 25 prompts, 1260.741 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv  get_availabl: prompt cache update took 12.05 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 522 | processing task, is_child = 0
slot update_slots: id  2 | task 526 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 150
slot update_slots: id  2 | task 526 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 526 | prompt processing progress, n_tokens = 150, batch.n_tokens = 75, progress = 1.000000
slot update_slots: id  2 | task 526 | prompt done, n_tokens = 150, batch.n_tokens = 75
slot init_sampler: id  2 | task 526 | init sampler, took 0.02 ms, tokens: text = 150, total = 150
slot update_slots: id  3 | task 522 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 219
slot update_slots: id  3 | task 522 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 522 | prompt processing progress, n_tokens = 219, batch.n_tokens = 217, progress = 1.000000
slot update_slots: id  3 | task 522 | prompt done, n_tokens = 219, batch.n_tokens = 217
slot init_sampler: id  3 | task 522 | init sampler, took 0.02 ms, tokens: text = 219, total = 219
srv  params_from_: Chat format: Content-only
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 515 | 
prompt eval time =     346.34 ms /    14 tokens (   24.74 ms per token,    40.42 tokens per second)
       eval time =    4687.25 ms /    11 tokens (  426.11 ms per token,     2.35 tokens per second)
      total time =    5033.59 ms /    25 tokens
slot      release: id  0 | task 515 | stop processing: n_tokens = 101, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.762
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 533 | processing task, is_child = 0
slot update_slots: id  0 | task 533 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 79
slot update_slots: id  0 | task 533 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 533 | prompt processing progress, n_tokens = 79, batch.n_tokens = 5, progress = 1.000000
slot update_slots: id  0 | task 533 | prompt done, n_tokens = 79, batch.n_tokens = 5
slot init_sampler: id  0 | task 533 | init sampler, took 0.01 ms, tokens: text = 79, total = 79
slot print_timing: id  1 | task 518 | 
prompt eval time =     349.64 ms /    10 tokens (   34.96 ms per token,    28.60 tokens per second)
       eval time =    5319.57 ms /    13 tokens (  409.20 ms per token,     2.44 tokens per second)
      total time =    5669.21 ms /    23 tokens
slot      release: id  1 | task 518 | stop processing: n_tokens = 99, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.778
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 536 | processing task, is_child = 0
slot update_slots: id  1 | task 536 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 81
slot update_slots: id  1 | task 536 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 536 | prompt processing progress, n_tokens = 81, batch.n_tokens = 7, progress = 1.000000
slot update_slots: id  1 | task 536 | prompt done, n_tokens = 81, batch.n_tokens = 7
slot init_sampler: id  1 | task 536 | init sampler, took 0.01 ms, tokens: text = 81, total = 81
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 522 | 
prompt eval time =    2014.78 ms /   142 tokens (   14.19 ms per token,    70.48 tokens per second)
       eval time =    2943.49 ms /    10 tokens (  294.35 ms per token,     3.40 tokens per second)
      total time =    4958.27 ms /   152 tokens
slot      release: id  3 | task 522 | stop processing: n_tokens = 228, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.819 (> 0.100 thold), f_keep = 0.338
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 228, total state size = 35.629 MiB
srv          load:  - looking for better prompt, base f_keep = 0.338, sim = 0.819
srv        update:  - cache state: 26 prompts, 1296.369 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv        update:    - prompt 0xbdb0f5610:     228 tokens, checkpoints:  0,    35.629 MiB
srv  get_availabl: prompt cache update took 5.58 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 538 | processing task, is_child = 0
slot update_slots: id  3 | task 538 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 94
slot update_slots: id  3 | task 538 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 538 | prompt processing progress, n_tokens = 94, batch.n_tokens = 20, progress = 1.000000
slot update_slots: id  3 | task 538 | prompt done, n_tokens = 94, batch.n_tokens = 20
slot init_sampler: id  3 | task 538 | init sampler, took 0.01 ms, tokens: text = 94, total = 94
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 526 | 
prompt eval time =    2008.03 ms /    73 tokens (   27.51 ms per token,    36.35 tokens per second)
       eval time =    4169.40 ms /    14 tokens (  297.81 ms per token,     3.36 tokens per second)
      total time =    6177.43 ms /    87 tokens
slot      release: id  2 | task 526 | stop processing: n_tokens = 163, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.324 (> 0.100 thold), f_keep = 0.472
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 163, total state size = 25.472 MiB
srv          load:  - looking for better prompt, base f_keep = 0.472, sim = 0.324
srv        update:  - cache state: 27 prompts, 1321.841 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv        update:    - prompt 0xbdb0f5610:     228 tokens, checkpoints:  0,    35.629 MiB
srv        update:    - prompt 0xbdb0f5690:     163 tokens, checkpoints:  0,    25.472 MiB
srv  get_availabl: prompt cache update took 5.27 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 543 | processing task, is_child = 0
slot update_slots: id  2 | task 543 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 238
slot update_slots: id  2 | task 543 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 543 | prompt processing progress, n_tokens = 238, batch.n_tokens = 164, progress = 1.000000
slot update_slots: id  2 | task 543 | prompt done, n_tokens = 238, batch.n_tokens = 164
slot init_sampler: id  2 | task 543 | init sampler, took 0.02 ms, tokens: text = 238, total = 238
srv  params_from_: Chat format: Content-only
slot print_timing: id  0 | task 533 | 
prompt eval time =     397.36 ms /     2 tokens (  198.68 ms per token,     5.03 tokens per second)
       eval time =    5177.13 ms /    13 tokens (  398.24 ms per token,     2.51 tokens per second)
      total time =    5574.49 ms /    15 tokens
slot      release: id  0 | task 533 | stop processing: n_tokens = 91, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.875 (> 0.100 thold), f_keep = 0.846
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 550 | processing task, is_child = 0
slot update_slots: id  0 | task 550 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 88
slot update_slots: id  0 | task 550 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 550 | prompt processing progress, n_tokens = 88, batch.n_tokens = 14, progress = 1.000000
slot update_slots: id  0 | task 550 | prompt done, n_tokens = 88, batch.n_tokens = 14
slot init_sampler: id  0 | task 550 | init sampler, took 0.01 ms, tokens: text = 88, total = 88
slot print_timing: id  1 | task 536 | 
prompt eval time =     513.49 ms /     4 tokens (  128.37 ms per token,     7.79 tokens per second)
       eval time =    4157.02 ms /    10 tokens (  415.70 ms per token,     2.41 tokens per second)
      total time =    4670.51 ms /    14 tokens
slot      release: id  1 | task 536 | stop processing: n_tokens = 90, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.570 (> 0.100 thold), f_keep = 0.856
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 551 | processing task, is_child = 0
slot update_slots: id  1 | task 551 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 135
slot update_slots: id  1 | task 551 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 551 | prompt processing progress, n_tokens = 135, batch.n_tokens = 61, progress = 1.000000
slot update_slots: id  1 | task 551 | prompt done, n_tokens = 135, batch.n_tokens = 61
slot init_sampler: id  1 | task 551 | init sampler, took 0.01 ms, tokens: text = 135, total = 135
srv  params_from_: Chat format: Content-only
slot print_timing: id  3 | task 538 | 
prompt eval time =     349.06 ms /    17 tokens (   20.53 ms per token,    48.70 tokens per second)
       eval time =    4696.85 ms /    11 tokens (  426.99 ms per token,     2.34 tokens per second)
      total time =    5045.91 ms /    28 tokens
slot      release: id  3 | task 538 | stop processing: n_tokens = 104, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.271 (> 0.100 thold), f_keep = 0.740
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 553 | processing task, is_child = 0
slot update_slots: id  3 | task 553 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 284
slot update_slots: id  3 | task 553 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 553 | prompt processing progress, n_tokens = 284, batch.n_tokens = 210, progress = 1.000000
slot update_slots: id  3 | task 553 | prompt done, n_tokens = 284, batch.n_tokens = 210
slot init_sampler: id  3 | task 553 | init sampler, took 0.03 ms, tokens: text = 284, total = 284
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot print_timing: id  2 | task 543 | 
prompt eval time =    1709.14 ms /   161 tokens (   10.62 ms per token,    94.20 tokens per second)
       eval time =    4696.52 ms /    10 tokens (  469.65 ms per token,     2.13 tokens per second)
      total time =    6405.66 ms /   171 tokens
slot      release: id  2 | task 543 | stop processing: n_tokens = 247, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: Content-only
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.341 (> 0.100 thold), f_keep = 0.312
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 247, total state size = 38.598 MiB
srv          load:  - looking for better prompt, base f_keep = 0.312, sim = 0.341
srv        update:  - cache state: 28 prompts, 1360.438 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv        update:    - prompt 0xbdb0f5610:     228 tokens, checkpoints:  0,    35.629 MiB
srv        update:    - prompt 0xbdb0f5690:     163 tokens, checkpoints:  0,    25.472 MiB
srv        update:    - prompt 0xbdb0f5710:     247 tokens, checkpoints:  0,    38.598 MiB
srv  get_availabl: prompt cache update took 6.75 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 560 | processing task, is_child = 0
slot update_slots: id  2 | task 560 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 226
slot update_slots: id  2 | task 560 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 560 | prompt processing progress, n_tokens = 226, batch.n_tokens = 152, progress = 1.000000
slot update_slots: id  2 | task 560 | prompt done, n_tokens = 226, batch.n_tokens = 152
slot init_sampler: id  2 | task 560 | init sampler, took 0.02 ms, tokens: text = 226, total = 226
slot print_timing: id  0 | task 550 | 
prompt eval time =     343.24 ms /    11 tokens (   31.20 ms per token,    32.05 tokens per second)
       eval time =    6104.19 ms /    11 tokens (  554.93 ms per token,     1.80 tokens per second)
      total time =    6447.43 ms /    22 tokens
slot      release: id  0 | task 550 | stop processing: n_tokens = 98, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.160 (> 0.100 thold), f_keep = 0.786
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 564 | processing task, is_child = 0
slot update_slots: id  0 | task 564 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 482
slot update_slots: id  0 | task 564 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 564 | prompt processing progress, n_tokens = 482, batch.n_tokens = 408, progress = 1.000000
slot update_slots: id  0 | task 564 | prompt done, n_tokens = 482, batch.n_tokens = 408
srv  params_from_: Chat format: Content-only
slot init_sampler: id  0 | task 564 | init sampler, took 0.05 ms, tokens: text = 482, total = 482
slot print_timing: id  1 | task 551 | 
prompt eval time =     602.22 ms /    58 tokens (   10.38 ms per token,    96.31 tokens per second)
       eval time =    8884.15 ms /    10 tokens (  888.41 ms per token,     1.13 tokens per second)
      total time =    9486.36 ms /    68 tokens
slot      release: id  1 | task 551 | stop processing: n_tokens = 144, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.520 (> 0.100 thold), f_keep = 0.535
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 569 | processing task, is_child = 0
slot update_slots: id  1 | task 569 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 148
slot update_slots: id  1 | task 569 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 569 | prompt processing progress, n_tokens = 148, batch.n_tokens = 74, progress = 1.000000
slot update_slots: id  1 | task 569 | prompt done, n_tokens = 148, batch.n_tokens = 74
slot init_sampler: id  1 | task 569 | init sampler, took 0.01 ms, tokens: text = 148, total = 148
slot print_timing: id  3 | task 553 | 
prompt eval time =    2003.80 ms /   207 tokens (    9.68 ms per token,   103.30 tokens per second)
       eval time =    8648.10 ms /    13 tokens (  665.24 ms per token,     1.50 tokens per second)
      total time =   10651.90 ms /   220 tokens
slot      release: id  3 | task 553 | stop processing: n_tokens = 296, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.260
srv  get_availabl: updating prompt cache
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv   prompt_save:  - saving prompt with length 296, total state size = 46.254 MiB
srv          load:  - looking for better prompt, base f_keep = 0.260, sim = 0.962
srv        update:  - cache state: 29 prompts, 1406.693 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv        update:    - prompt 0xbdb0f5610:     228 tokens, checkpoints:  0,    35.629 MiB
srv        update:    - prompt 0xbdb0f5690:     163 tokens, checkpoints:  0,    25.472 MiB
srv        update:    - prompt 0xbdb0f5710:     247 tokens, checkpoints:  0,    38.598 MiB
srv        update:    - prompt 0xbdb0f5790:     296 tokens, checkpoints:  0,    46.254 MiB
srv  get_availabl: prompt cache update took 10.12 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 570 | processing task, is_child = 0
slot update_slots: id  3 | task 570 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 80
slot update_slots: id  3 | task 570 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  3 | task 570 | prompt processing progress, n_tokens = 80, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  3 | task 570 | prompt done, n_tokens = 80, batch.n_tokens = 6
slot init_sampler: id  3 | task 570 | init sampler, took 0.01 ms, tokens: text = 80, total = 80
slot print_timing: id  1 | task 569 | 
prompt eval time =     898.95 ms /    71 tokens (   12.66 ms per token,    78.98 tokens per second)
       eval time =    2736.34 ms /    10 tokens (  273.63 ms per token,     3.65 tokens per second)
      total time =    3635.28 ms /    81 tokens
slot      release: id  1 | task 569 | stop processing: n_tokens = 157, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  1 | task -1 | selected slot by LCP similarity, sim_best = 0.928 (> 0.100 thold), f_keep = 0.490
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 157, total state size = 24.534 MiB
srv          load:  - looking for better prompt, base f_keep = 0.490, sim = 0.928
srv        update:  - cache state: 30 prompts, 1431.226 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv        update:    - prompt 0xbdb0f5610:     228 tokens, checkpoints:  0,    35.629 MiB
srv        update:    - prompt 0xbdb0f5690:     163 tokens, checkpoints:  0,    25.472 MiB
srv        update:    - prompt 0xbdb0f5710:     247 tokens, checkpoints:  0,    38.598 MiB
srv        update:    - prompt 0xbdb0f5790:     296 tokens, checkpoints:  0,    46.254 MiB
srv        update:    - prompt 0xbdb0f5810:     157 tokens, checkpoints:  0,    24.534 MiB
srv  get_availabl: prompt cache update took 2.98 ms
slot launch_slot_: id  1 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  1 | task 574 | processing task, is_child = 0
slot update_slots: id  1 | task 574 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 83
slot update_slots: id  1 | task 574 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  1 | task 574 | prompt processing progress, n_tokens = 83, batch.n_tokens = 9, progress = 1.000000
slot update_slots: id  1 | task 574 | prompt done, n_tokens = 83, batch.n_tokens = 9
slot init_sampler: id  1 | task 574 | init sampler, took 0.01 ms, tokens: text = 83, total = 83
slot print_timing: id  2 | task 560 | 
prompt eval time =    1450.50 ms /   149 tokens (    9.73 ms per token,   102.72 tokens per second)
       eval time =    7949.08 ms /    14 tokens (  567.79 ms per token,     1.76 tokens per second)
      total time =    9399.58 ms /   163 tokens
slot      release: id  2 | task 560 | stop processing: n_tokens = 239, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.856 (> 0.100 thold), f_keep = 0.322
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 239, total state size = 37.347 MiB
srv          load:  - looking for better prompt, base f_keep = 0.322, sim = 0.856
srv        update:  - cache state: 31 prompts, 1468.574 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv        update:    - prompt 0xbdb0f5610:     228 tokens, checkpoints:  0,    35.629 MiB
srv        update:    - prompt 0xbdb0f5690:     163 tokens, checkpoints:  0,    25.472 MiB
srv        update:    - prompt 0xbdb0f5710:     247 tokens, checkpoints:  0,    38.598 MiB
srv        update:    - prompt 0xbdb0f5790:     296 tokens, checkpoints:  0,    46.254 MiB
srv        update:    - prompt 0xbdb0f5810:     157 tokens, checkpoints:  0,    24.534 MiB
srv        update:    - prompt 0xbdb0f5890:     239 tokens, checkpoints:  0,    37.347 MiB
srv  get_availabl: prompt cache update took 7.47 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 579 | processing task, is_child = 0
slot update_slots: id  2 | task 579 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 90
slot update_slots: id  2 | task 579 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  2 | task 579 | prompt processing progress, n_tokens = 90, batch.n_tokens = 16, progress = 1.000000
slot update_slots: id  2 | task 579 | prompt done, n_tokens = 90, batch.n_tokens = 16
slot init_sampler: id  2 | task 579 | init sampler, took 0.01 ms, tokens: text = 90, total = 90
slot print_timing: id  0 | task 564 | 
prompt eval time =    3674.87 ms /   405 tokens (    9.07 ms per token,   110.21 tokens per second)
       eval time =    4646.60 ms /    14 tokens (  331.90 ms per token,     3.01 tokens per second)
      total time =    8321.47 ms /   419 tokens
slot      release: id  0 | task 564 | stop processing: n_tokens = 495, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot get_availabl: id  0 | task -1 | selected slot by LCP similarity, sim_best = 0.778 (> 0.100 thold), f_keep = 0.156
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 495, total state size = 77.350 MiB
srv          load:  - looking for better prompt, base f_keep = 0.156, sim = 0.778
srv        update:  - cache state: 32 prompts, 1545.924 MiB (limits: 8192.000 MiB, 90880 tokens, 90880 est)
srv        update:    - prompt 0xbdb0f4a90:     628 tokens, checkpoints:  0,    98.133 MiB
srv        update:    - prompt 0xbdb0f4c10:     164 tokens, checkpoints:  0,    25.628 MiB
srv        update:    - prompt 0xbdb0f4b90:     258 tokens, checkpoints:  0,    40.316 MiB
srv        update:    - prompt 0xbdb0f4990:     160 tokens, checkpoints:  0,    25.003 MiB
srv        update:    - prompt 0xbdb0f4a10:     116 tokens, checkpoints:  0,    18.127 MiB
srv        update:    - prompt 0xbdb0f4b10:     205 tokens, checkpoints:  0,    32.035 MiB
srv        update:    - prompt 0xbdb0f4d10:     983 tokens, checkpoints:  0,   153.606 MiB
srv        update:    - prompt 0xbdb0f4d90:     197 tokens, checkpoints:  0,    30.784 MiB
srv        update:    - prompt 0xbdb0f4c90:     283 tokens, checkpoints:  0,    44.223 MiB
srv        update:    - prompt 0xbdb0f4e10:     186 tokens, checkpoints:  0,    29.066 MiB
srv        update:    - prompt 0xbdb0f4e90:     242 tokens, checkpoints:  0,    37.816 MiB
srv        update:    - prompt 0xbdb0f4f10:     156 tokens, checkpoints:  0,    24.378 MiB
srv        update:    - prompt 0xbdb0f4f90:     189 tokens, checkpoints:  0,    29.534 MiB
srv        update:    - prompt 0xbdb0f5010:     216 tokens, checkpoints:  0,    33.753 MiB
srv        update:    - prompt 0xbdb0f5090:     175 tokens, checkpoints:  0,    27.347 MiB
srv        update:    - prompt 0xbdb0f5110:     231 tokens, checkpoints:  0,    36.097 MiB
srv        update:    - prompt 0xbdb0f5190:     724 tokens, checkpoints:  0,   113.134 MiB
srv        update:    - prompt 0xbdb0f5210:     333 tokens, checkpoints:  0,    52.036 MiB
srv        update:    - prompt 0xbdb0f5290:     752 tokens, checkpoints:  0,   117.510 MiB
srv        update:    - prompt 0xbdb0f5310:     524 tokens, checkpoints:  0,    81.882 MiB
srv        update:    - prompt 0xbdb0f5390:     543 tokens, checkpoints:  0,    84.851 MiB
srv        update:    - prompt 0xbdb0f5410:     185 tokens, checkpoints:  0,    28.909 MiB
srv        update:    - prompt 0xbdb0f5490:     179 tokens, checkpoints:  0,    27.972 MiB
srv        update:    - prompt 0xbdb0f5510:     162 tokens, checkpoints:  0,    25.315 MiB
srv        update:    - prompt 0xbdb0f5590:     277 tokens, checkpoints:  0,    43.285 MiB
srv        update:    - prompt 0xbdb0f5610:     228 tokens, checkpoints:  0,    35.629 MiB
srv        update:    - prompt 0xbdb0f5690:     163 tokens, checkpoints:  0,    25.472 MiB
srv        update:    - prompt 0xbdb0f5710:     247 tokens, checkpoints:  0,    38.598 MiB
srv        update:    - prompt 0xbdb0f5790:     296 tokens, checkpoints:  0,    46.254 MiB
srv        update:    - prompt 0xbdb0f5810:     157 tokens, checkpoints:  0,    24.534 MiB
srv        update:    - prompt 0xbdb0f5890:     239 tokens, checkpoints:  0,    37.347 MiB
srv        update:    - prompt 0xbdb0f5910:     495 tokens, checkpoints:  0,    77.350 MiB
srv  get_availabl: prompt cache update took 12.73 ms
slot launch_slot_: id  0 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  0 | task 582 | processing task, is_child = 0
slot update_slots: id  0 | task 582 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 99
slot update_slots: id  0 | task 582 | n_tokens = 77, memory_seq_rm [77, end)
slot update_slots: id  0 | task 582 | prompt processing progress, n_tokens = 99, batch.n_tokens = 25, progress = 1.000000
slot update_slots: id  0 | task 582 | prompt done, n_tokens = 99, batch.n_tokens = 25
slot init_sampler: id  0 | task 582 | init sampler, took 0.01 ms, tokens: text = 99, total = 99
slot print_timing: id  3 | task 570 | 
prompt eval time =     406.43 ms /     3 tokens (  135.48 ms per token,     7.38 tokens per second)
       eval time =    3101.64 ms /    11 tokens (  281.97 ms per token,     3.55 tokens per second)
      total time =    3508.07 ms /    14 tokens
slot      release: id  3 | task 570 | stop processing: n_tokens = 90, truncated = 0
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.438 (> 0.100 thold), f_keep = 0.856
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 586 | processing task, is_child = 0
slot update_slots: id  3 | task 586 | new prompt, n_ctx_slot = 90880, n_keep = 0, task.n_tokens = 176
slot update_slots: id  3 | task 586 | n_tokens = 77, memory_seq_rm [77, end)
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot update_slots: id  3 | task 586 | prompt processing progress, n_tokens = 176, batch.n_tokens = 102, progress = 1.000000
slot update_slots: id  3 | task 586 | prompt done, n_tokens = 176, batch.n_tokens = 102
slot init_sampler: id  3 | task 586 | init sampler, took 0.02 ms, tokens: text = 176, total = 176
slot print_timing: id  1 | task 574 | 
prompt eval time =     339.30 ms /     6 tokens (   56.55 ms per token,    17.68 tokens per second)
       eval time =    3913.39 ms /    11 tokens (  355.76 ms per token,     2.81 tokens per second)
      total time =    4252.69 ms /    17 tokens
slot      release: id  1 | task 574 | stop processing: n_tokens = 93, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  2 | task 579 | 
prompt eval time =     358.25 ms /    13 tokens (   27.56 ms per token,    36.29 tokens per second)
       eval time =    3540.64 ms /    10 tokens (  354.06 ms per token,     2.82 tokens per second)
      total time =    3898.88 ms /    23 tokens
slot      release: id  2 | task 579 | stop processing: n_tokens = 99, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  0 | task 582 | 
prompt eval time =     342.38 ms /    22 tokens (   15.56 ms per token,    64.26 tokens per second)
       eval time =    3652.89 ms /    14 tokens (  260.92 ms per token,     3.83 tokens per second)
      total time =    3995.27 ms /    36 tokens
slot      release: id  0 | task 582 | stop processing: n_tokens = 112, truncated = 0
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
slot print_timing: id  3 | task 586 | 
prompt eval time =    1162.82 ms /    99 tokens (   11.75 ms per token,    85.14 tokens per second)
       eval time =    1865.51 ms /    14 tokens (  133.25 ms per token,     7.50 tokens per second)
      total time =    3028.33 ms /   113 tokens
slot      release: id  3 | task 586 | stop processing: n_tokens = 189, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: done request: POST /v1/chat/completions 127.0.0.1 200
srv    operator(): operator(): cleaning up before exit...
llama_memory_breakdown_print: | memory breakdown [MiB]  | total   free     self   model   context   compute    unaccounted |
llama_memory_breakdown_print: |   - MTL0 (Apple M3 Pro) | 28753 =  532 + (28220 = 13672 +   14200 +     348) +           0 |
llama_memory_breakdown_print: |   - Host                |                   722 =   525 +       0 +     197                |
ggml_metal_free: deallocating
